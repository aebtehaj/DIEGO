{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Training d-DNN and e-DNNs using DPR coincidences over the coast**"
      ],
      "metadata": {
        "id": "s6rIIA1uPxCf"
      },
      "id": "s6rIIA1uPxCf"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "import tensorflow as tf\n",
        "import os"
      ],
      "metadata": {
        "id": "hYNvEy8qPydm"
      },
      "id": "hYNvEy8qPydm",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SUEceIZNPtfo",
        "outputId": "770a964e-1d1a-4dc2-bf4d-00b0cfe1ec5d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['X_coast_trn_detection',\n",
              " 'X_coast_tst_detection',\n",
              " 'X_rain_coast_trn_retrieval',\n",
              " 'X_rain_coast_tst_retrieval',\n",
              " 'X_snow_coast_trn_retrieval',\n",
              " 'X_snow_coast_tst_retrieval',\n",
              " 'y_coast_trn_detection',\n",
              " 'y_coast_tst_detection',\n",
              " 'y_rain_coast_trn_retrieval',\n",
              " 'y_rain_coast_tst_retrieval',\n",
              " 'y_snow_coast_trn_retrieval',\n",
              " 'y_snow_coast_tst_retrieval']"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = h5py.File('Data/Dictionaries/Dic_DPR_coast.mat','r')\n",
        "list(f.keys())"
      ],
      "id": "SUEceIZNPtfo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uDDiiu3APtfo"
      },
      "outputs": [],
      "source": [
        "X1_trn_detection = np.transpose(f['X_coast_trn_detection'])\n",
        "y_trn_detection = np.transpose(f['y_coast_trn_detection'])\n",
        "X1_tst_detection = np.transpose(f['X_coast_tst_detection'])\n",
        "y_tst_detection = np.transpose(f['y_coast_tst_detection'])\n",
        "\n",
        "X1_rain_trn_retrieval = np.transpose(f['X_rain_coast_trn_retrieval'])\n",
        "y_rain_trn_retrieval = np.transpose(f['y_rain_coast_trn_retrieval'])\n",
        "X1_rain_tst_retrieval = np.transpose(f['X_rain_coast_tst_retrieval'])\n",
        "y_rain_tst_retrieval = np.transpose(f['y_rain_coast_tst_retrieval'])\n",
        "\n",
        "X1_snow_trn_retrieval = np.transpose(f['X_snow_coast_trn_retrieval'])\n",
        "y_snow_trn_retrieval = np.transpose(f['y_snow_coast_trn_retrieval'])\n",
        "X1_snow_tst_retrieval = np.transpose(f['X_snow_coast_tst_retrieval'])\n",
        "y_snow_tst_retrieval = np.transpose(f['y_snow_coast_tst_retrieval'])"
      ],
      "id": "uDDiiu3APtfo"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "obJmwhPlPtfp"
      },
      "outputs": [],
      "source": [
        "X1_trn_detection.astype('float64')\n",
        "X1_tst_detection.astype('float64')\n",
        "y_trn_detection.astype('int64')\n",
        "y_tst_detection.astype('int64')\n",
        "\n",
        "X1_rain_trn_retrieval.astype('float64')\n",
        "X1_rain_tst_retrieval.astype('float64')\n",
        "y_rain_trn_retrieval.astype('float64')\n",
        "y_rain_tst_retrieval.astype('float64')\n",
        "\n",
        "X1_snow_trn_retrieval.astype('float64')\n",
        "X1_snow_tst_retrieval.astype('float64')\n",
        "y_snow_trn_retrieval.astype('float64')\n",
        "y_snow_tst_retrieval.astype('float64');"
      ],
      "id": "obJmwhPlPtfp"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Data Normalizing**\n",
        "\n",
        "The input features for training have different ranges and units, therefore they need to be scaled to make the flow of the gradient decsent smooth and help the algorithm quickly reaches the optimal point of the cost function. Without scaling features, the algorithm may be biased toward those features which have larger magnitues. We used the following standardization:\n",
        "\n",
        "$X_i^{\\prime} = \\frac{X_i - \\mu}{σ}$\n",
        "\n",
        "In the above equation $X_i^{\\prime}$ is the scaled feature, $μ$ is the mean, and $σ$ is the standard deviation of the feature. In the next cell, we implement this scaling for the data sets."
      ],
      "metadata": {
        "id": "b-AAQgJiUB4v"
      },
      "id": "b-AAQgJiUB4v"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S7KowTpwPtfp"
      },
      "outputs": [],
      "source": [
        "mean_detection = X1_trn_detection.mean(axis=0)\n",
        "X2_trn_detection = X1_trn_detection-mean_detection\n",
        "std_detection = X1_trn_detection.std(axis=0)\n",
        "X_trn_detection = X2_trn_detection/std_detection\n",
        "X2_tst_detection = X1_tst_detection-mean_detection\n",
        "X_tst_detection = X2_tst_detection/std_detection\n",
        "\n",
        "mean_rain_retrieval = X1_rain_trn_retrieval.mean(axis=0)\n",
        "X2_rain_trn_retrieval = X1_rain_trn_retrieval-mean_rain_retrieval\n",
        "std_rain_retrieval = X1_rain_trn_retrieval.std(axis=0)\n",
        "X_rain_trn_retrieval = X2_rain_trn_retrieval/std_rain_retrieval\n",
        "X2_rain_tst_retrieval = X1_rain_tst_retrieval-mean_rain_retrieval\n",
        "X_rain_tst_retrieval = X2_rain_tst_retrieval/std_rain_retrieval\n",
        "\n",
        "mean_snow_retrieval = X1_snow_trn_retrieval.mean(axis=0)\n",
        "X2_snow_trn_retrieval = X1_snow_trn_retrieval-mean_snow_retrieval\n",
        "std_snow_retrieval = X1_snow_trn_retrieval.std(axis=0)\n",
        "X_snow_trn_retrieval = X2_snow_trn_retrieval/std_snow_retrieval\n",
        "X2_snow_tst_retrieval = X1_snow_tst_retrieval-mean_snow_retrieval\n",
        "X_snow_tst_retrieval = X2_snow_tst_retrieval/std_snow_retrieval"
      ],
      "id": "S7KowTpwPtfp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uSVuFFWlPtfq",
        "outputId": "009f5331-8ba3-4bc9-a073-e1c42ff8fb94"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(0.01, 13.24145379142524, 0.01, 109.59234032238346)"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Removing the outliers\n",
        "x_snow_lb = 0.01 #np.percentile(y_snow_trn_retrieval,0.05)\n",
        "x_snow_ub = np.percentile(y_snow_trn_retrieval,99.95)\n",
        "\n",
        "x_rain_lb = 0.01 #np.percentile(y_rain_trn_retrieval,0.05)\n",
        "x_rain_ub = np.percentile(y_rain_trn_retrieval,99.95)\n",
        "\n",
        "mask_trn_snow = (y_snow_trn_retrieval>=x_snow_lb) & (y_snow_trn_retrieval<=x_snow_ub)\n",
        "m_trn_snow=mask_trn_snow[:,0]\n",
        "mask_tst_snow = (y_snow_tst_retrieval>=x_snow_lb) & (y_snow_tst_retrieval<=x_snow_ub)\n",
        "m_tst_snow=mask_tst_snow[:,0]\n",
        "\n",
        "mask_trn_rain = (y_rain_trn_retrieval>=x_rain_lb) & (y_rain_trn_retrieval<=x_rain_ub)\n",
        "m_trn_rain=mask_trn_rain[:,0]\n",
        "mask_tst_rain = (y_rain_tst_retrieval>=x_rain_lb) & (y_rain_tst_retrieval<=x_rain_ub)\n",
        "m_tst_rain=mask_tst_rain[:,0]\n",
        "\n",
        "Xf_snow_trn_detection = np.delete(X_trn_detection, ~m_trn_snow, axis=0)\n",
        "yf_snow_trn_detection = np.delete(y_trn_detection, ~m_trn_snow, axis=0)\n",
        "Xf_snow_tst_detection = np.delete(X_tst_detection, ~m_tst_snow, axis=0)\n",
        "yf_snow_tst_detection = np.delete(y_tst_detection, ~m_tst_snow, axis=0)\n",
        "\n",
        "Xf_snow_trn_retrieval = np.delete(X_snow_trn_retrieval, ~m_trn_snow, axis=0)\n",
        "yf_snow_trn_retrieval = np.delete(y_snow_trn_retrieval, ~m_trn_snow, axis=0)\n",
        "Xf_snow_tst_retrieval = np.delete(X_snow_tst_retrieval, ~m_tst_snow, axis=0)\n",
        "yf_snow_tst_retrieval = np.delete(y_snow_tst_retrieval, ~m_tst_snow, axis=0)\n",
        "\n",
        "Xf_rain_trn_detection = np.delete(X_trn_detection, ~m_trn_rain, axis=0)\n",
        "yf_rain_trn_detection = np.delete(y_trn_detection, ~m_trn_rain, axis=0)\n",
        "Xf_rain_tst_detection = np.delete(X_tst_detection, ~m_tst_rain, axis=0)\n",
        "yf_rain_tst_detection = np.delete(y_tst_detection, ~m_tst_rain, axis=0)\n",
        "\n",
        "Xf_rain_trn_retrieval = np.delete(X_rain_trn_retrieval, ~m_trn_rain, axis=0)\n",
        "yf_rain_trn_retrieval = np.delete(y_rain_trn_retrieval, ~m_trn_rain, axis=0)\n",
        "Xf_rain_tst_retrieval = np.delete(X_rain_tst_retrieval, ~m_tst_rain, axis=0)\n",
        "yf_rain_tst_retrieval = np.delete(y_rain_tst_retrieval, ~m_tst_rain, axis=0)\n",
        "\n",
        "x_snow_lb, x_snow_ub, x_rain_lb, x_rain_ub"
      ],
      "id": "uSVuFFWlPtfq"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show that the labels are balanced in the training and test set, the number of snowfall, rainfall and no precipitation lables is printed in the next cell."
      ],
      "metadata": {
        "id": "i4ZbJ1wsUJgW"
      },
      "id": "i4ZbJ1wsUJgW"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TC2t7FJMPtfq",
        "outputId": "6d05f126-0d23-4900-9d40-5f5794a12d40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***Training Dataset:\n",
            "\n",
            "Num. of snowfall: 175023\n",
            "Num. of rainfall: 175161\n",
            "Num. of clear-sky: 349819\n",
            "\n",
            "***Testing Dataset:\n",
            "\n",
            "Num. of snowfall: 75172\n",
            "Num. of rainfall: 74613\n",
            "Num. of clear-sky: 150218\n"
          ]
        }
      ],
      "source": [
        "print('***Training Dataset:\\n')\n",
        "\n",
        "n_snow=1\n",
        "n_rain=1\n",
        "n_clear=1  \n",
        "t_train = np.zeros([y_trn_detection.shape[0],1])\n",
        "\n",
        "for i in range(len(X_trn_detection)):\n",
        "    label = y_trn_detection[i]\n",
        "    if label==1:\n",
        "        n_snow+=1\n",
        "        t_train[i]=2\n",
        "    if label==2:\n",
        "        n_rain+=1  \n",
        "        t_train[i]=1\n",
        "    if label==3:\n",
        "        n_clear+=1\n",
        "        t_train[i]=0\n",
        "        \n",
        "print('Num. of snowfall:',n_snow)\n",
        "print('Num. of rainfall:',n_rain)\n",
        "print('Num. of clear-sky:',n_clear)\n",
        "\n",
        "print('\\n***Testing Dataset:\\n')\n",
        "\n",
        "n_snow=1\n",
        "n_rain=1\n",
        "n_clear=1  \n",
        "t_test = np.zeros([y_tst_detection.shape[0],1])\n",
        "\n",
        "for i in range(len(X_tst_detection)):\n",
        "    label = y_tst_detection[i]\n",
        "    if label==1:\n",
        "        n_snow+=1\n",
        "        t_test[i]=2\n",
        "    if label==2:\n",
        "        n_rain+=1  \n",
        "        t_test[i]=1\n",
        "    if label==3:\n",
        "        n_clear+=1\n",
        "        t_test[i]=0\n",
        "        \n",
        "print('Num. of snowfall:',n_snow)\n",
        "print('Num. of rainfall:',n_rain)\n",
        "print('Num. of clear-sky:',n_clear)"
      ],
      "id": "TC2t7FJMPtfq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Cm9c0uqEPtfr"
      },
      "outputs": [],
      "source": [
        "# Change the labels to catagorical\n",
        "\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "t_trn_detection = to_categorical(t_train)\n",
        "t_tst_detection = to_categorical(t_test)"
      ],
      "id": "Cm9c0uqEPtfr"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eWkIA0kiPtfr"
      },
      "source": [
        "# **2. Training the networks**"
      ],
      "id": "eWkIA0kiPtfr"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7gr_Yu9Ptfs"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import layers, Sequential"
      ],
      "id": "v7gr_Yu9Ptfs"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 - Detection Network (d-DNN)** "
      ],
      "metadata": {
        "id": "WGd5rbnkU1DQ"
      },
      "id": "WGd5rbnkU1DQ"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wVvrtfOjPtfs"
      },
      "outputs": [],
      "source": [
        "# Defining the architecture of the d-DNN network which has 6 layers and 30 hidden units in each layer.\n",
        "\n",
        "# Parameters\n",
        "hidden_units = 30\n",
        "dropout = 0\n",
        "\n",
        "# Detection Module\n",
        "model_detection = Sequential()\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(3))\n",
        "model_detection.add(Activation('softmax'))"
      ],
      "id": "wVvrtfOjPtfs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zC7C5iyPtfs"
      },
      "outputs": [],
      "source": [
        "# Compiling the model by defining the loss function and learning rate.\n",
        "\n",
        "model_detection.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics= [tf.keras.metrics.Recall()])"
      ],
      "id": "9zC7C5iyPtfs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qoyui9uGPtft"
      },
      "outputs": [],
      "source": [
        "# Defining the callback list for early stoping and saving the model.\n",
        "\n",
        "from tensorflow import keras\n",
        "callbacks_list = [\n",
        "#     keras.callbacks.EarlyStopping(\n",
        "#     monitor=\"val_loss\",\n",
        "#     patience=25,),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint_path.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    )    \n",
        "]"
      ],
      "id": "Qoyui9uGPtft"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n9ERTXMyPtft",
        "outputId": "0ad1abad-f1e2-4df1-add5-ade03c1d58e0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting DNN (Detection Module):\n",
            "\n",
            "Epoch 1/300\n",
            "312/312 [==============================] - 1s 4ms/step - loss: 0.8444 - recall: 0.3152 - val_loss: 0.6077 - val_recall: 0.6789\n",
            "Epoch 2/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.4905 - recall: 0.7663 - val_loss: 0.4162 - val_recall: 0.8148\n",
            "Epoch 3/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.3863 - recall: 0.8299 - val_loss: 0.3596 - val_recall: 0.8435\n",
            "Epoch 4/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.3464 - recall: 0.8503 - val_loss: 0.3304 - val_recall: 0.8580\n",
            "Epoch 5/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.3245 - recall: 0.8615 - val_loss: 0.3164 - val_recall: 0.8657\n",
            "Epoch 6/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.3121 - recall: 0.8680 - val_loss: 0.3093 - val_recall: 0.8703\n",
            "Epoch 7/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.3042 - recall: 0.8720 - val_loss: 0.2996 - val_recall: 0.8737\n",
            "Epoch 8/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2985 - recall: 0.8746 - val_loss: 0.2945 - val_recall: 0.8756\n",
            "Epoch 9/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2941 - recall: 0.8768 - val_loss: 0.2927 - val_recall: 0.8758\n",
            "Epoch 10/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2907 - recall: 0.8782 - val_loss: 0.2873 - val_recall: 0.8791\n",
            "Epoch 11/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2879 - recall: 0.8795 - val_loss: 0.2843 - val_recall: 0.8810\n",
            "Epoch 12/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2855 - recall: 0.8806 - val_loss: 0.2819 - val_recall: 0.8823\n",
            "Epoch 13/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2834 - recall: 0.8815 - val_loss: 0.2788 - val_recall: 0.8831\n",
            "Epoch 14/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2814 - recall: 0.8825 - val_loss: 0.2797 - val_recall: 0.8823\n",
            "Epoch 15/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2797 - recall: 0.8832 - val_loss: 0.2751 - val_recall: 0.8850\n",
            "Epoch 16/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2782 - recall: 0.8838 - val_loss: 0.2753 - val_recall: 0.8845\n",
            "Epoch 17/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2769 - recall: 0.8843 - val_loss: 0.2729 - val_recall: 0.8861\n",
            "Epoch 18/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2757 - recall: 0.8849 - val_loss: 0.2732 - val_recall: 0.8856\n",
            "Epoch 19/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2746 - recall: 0.8855 - val_loss: 0.2713 - val_recall: 0.8866\n",
            "Epoch 20/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2735 - recall: 0.8858 - val_loss: 0.2714 - val_recall: 0.8865\n",
            "Epoch 21/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2727 - recall: 0.8861 - val_loss: 0.2707 - val_recall: 0.8865\n",
            "Epoch 22/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2718 - recall: 0.8865 - val_loss: 0.2706 - val_recall: 0.8862\n",
            "Epoch 23/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2710 - recall: 0.8870 - val_loss: 0.2670 - val_recall: 0.8884\n",
            "Epoch 24/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2702 - recall: 0.8873 - val_loss: 0.2703 - val_recall: 0.8868\n",
            "Epoch 25/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2695 - recall: 0.8876 - val_loss: 0.2709 - val_recall: 0.8862\n",
            "Epoch 26/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2689 - recall: 0.8878 - val_loss: 0.2665 - val_recall: 0.8883\n",
            "Epoch 27/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2683 - recall: 0.8880 - val_loss: 0.2657 - val_recall: 0.8889\n",
            "Epoch 28/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2677 - recall: 0.8884 - val_loss: 0.2647 - val_recall: 0.8892\n",
            "Epoch 29/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2672 - recall: 0.8885 - val_loss: 0.2643 - val_recall: 0.8889\n",
            "Epoch 30/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2667 - recall: 0.8887 - val_loss: 0.2651 - val_recall: 0.8890\n",
            "Epoch 31/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2662 - recall: 0.8887 - val_loss: 0.2645 - val_recall: 0.8888\n",
            "Epoch 32/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2657 - recall: 0.8889 - val_loss: 0.2670 - val_recall: 0.8885\n",
            "Epoch 33/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2653 - recall: 0.8891 - val_loss: 0.2617 - val_recall: 0.8902\n",
            "Epoch 34/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2648 - recall: 0.8895 - val_loss: 0.2624 - val_recall: 0.8900\n",
            "Epoch 35/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2644 - recall: 0.8895 - val_loss: 0.2654 - val_recall: 0.8891\n",
            "Epoch 36/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2640 - recall: 0.8897 - val_loss: 0.2654 - val_recall: 0.8884\n",
            "Epoch 37/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2637 - recall: 0.8899 - val_loss: 0.2663 - val_recall: 0.8889\n",
            "Epoch 38/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2633 - recall: 0.8901 - val_loss: 0.2643 - val_recall: 0.8893\n",
            "Epoch 39/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2630 - recall: 0.8902 - val_loss: 0.2617 - val_recall: 0.8909\n",
            "Epoch 40/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2626 - recall: 0.8905 - val_loss: 0.2608 - val_recall: 0.8910\n",
            "Epoch 41/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2623 - recall: 0.8907 - val_loss: 0.2610 - val_recall: 0.8909\n",
            "Epoch 42/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2620 - recall: 0.8908 - val_loss: 0.2599 - val_recall: 0.8911\n",
            "Epoch 43/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2617 - recall: 0.8908 - val_loss: 0.2599 - val_recall: 0.8912\n",
            "Epoch 44/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2614 - recall: 0.8911 - val_loss: 0.2598 - val_recall: 0.8922\n",
            "Epoch 45/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2611 - recall: 0.8912 - val_loss: 0.2633 - val_recall: 0.8903\n",
            "Epoch 46/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2608 - recall: 0.8914 - val_loss: 0.2580 - val_recall: 0.8925\n",
            "Epoch 47/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2606 - recall: 0.8916 - val_loss: 0.2591 - val_recall: 0.8921\n",
            "Epoch 48/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2604 - recall: 0.8915 - val_loss: 0.2583 - val_recall: 0.8926\n",
            "Epoch 49/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2600 - recall: 0.8918 - val_loss: 0.2573 - val_recall: 0.8929\n",
            "Epoch 50/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2598 - recall: 0.8920 - val_loss: 0.2600 - val_recall: 0.8909\n",
            "Epoch 51/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2596 - recall: 0.8920 - val_loss: 0.2582 - val_recall: 0.8924\n",
            "Epoch 52/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2593 - recall: 0.8923 - val_loss: 0.2590 - val_recall: 0.8921\n",
            "Epoch 53/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2592 - recall: 0.8923 - val_loss: 0.2599 - val_recall: 0.8913\n",
            "Epoch 54/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2588 - recall: 0.8926 - val_loss: 0.2600 - val_recall: 0.8917\n",
            "Epoch 55/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2587 - recall: 0.8925 - val_loss: 0.2572 - val_recall: 0.8929\n",
            "Epoch 56/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2585 - recall: 0.8926 - val_loss: 0.2571 - val_recall: 0.8929\n",
            "Epoch 57/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2583 - recall: 0.8926 - val_loss: 0.2587 - val_recall: 0.8923\n",
            "Epoch 58/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2581 - recall: 0.8928 - val_loss: 0.2551 - val_recall: 0.8942\n",
            "Epoch 59/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2579 - recall: 0.8930 - val_loss: 0.2564 - val_recall: 0.8933\n",
            "Epoch 60/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2577 - recall: 0.8930 - val_loss: 0.2564 - val_recall: 0.8933\n",
            "Epoch 61/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2576 - recall: 0.8932 - val_loss: 0.2561 - val_recall: 0.8935\n",
            "Epoch 62/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2573 - recall: 0.8932 - val_loss: 0.2597 - val_recall: 0.8917\n",
            "Epoch 63/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2572 - recall: 0.8932 - val_loss: 0.2577 - val_recall: 0.8925\n",
            "Epoch 64/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2570 - recall: 0.8936 - val_loss: 0.2580 - val_recall: 0.8922\n",
            "Epoch 65/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2568 - recall: 0.8935 - val_loss: 0.2562 - val_recall: 0.8933\n",
            "Epoch 66/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2566 - recall: 0.8934 - val_loss: 0.2552 - val_recall: 0.8942\n",
            "Epoch 67/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2565 - recall: 0.8935 - val_loss: 0.2540 - val_recall: 0.8949\n",
            "Epoch 68/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2562 - recall: 0.8938 - val_loss: 0.2548 - val_recall: 0.8943\n",
            "Epoch 69/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2561 - recall: 0.8938 - val_loss: 0.2546 - val_recall: 0.8944\n",
            "Epoch 70/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2559 - recall: 0.8938 - val_loss: 0.2543 - val_recall: 0.8950\n",
            "Epoch 71/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2558 - recall: 0.8940 - val_loss: 0.2541 - val_recall: 0.8943\n",
            "Epoch 72/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2556 - recall: 0.8941 - val_loss: 0.2601 - val_recall: 0.8920\n",
            "Epoch 73/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2555 - recall: 0.8941 - val_loss: 0.2546 - val_recall: 0.8943\n",
            "Epoch 74/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2554 - recall: 0.8940 - val_loss: 0.2553 - val_recall: 0.8943\n",
            "Epoch 75/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2552 - recall: 0.8943 - val_loss: 0.2546 - val_recall: 0.8940\n",
            "Epoch 76/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2550 - recall: 0.8944 - val_loss: 0.2555 - val_recall: 0.8937\n",
            "Epoch 77/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2549 - recall: 0.8941 - val_loss: 0.2560 - val_recall: 0.8934\n",
            "Epoch 78/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2548 - recall: 0.8945 - val_loss: 0.2530 - val_recall: 0.8950\n",
            "Epoch 79/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2546 - recall: 0.8945 - val_loss: 0.2533 - val_recall: 0.8950\n",
            "Epoch 80/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2545 - recall: 0.8945 - val_loss: 0.2529 - val_recall: 0.8948\n",
            "Epoch 81/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2544 - recall: 0.8946 - val_loss: 0.2543 - val_recall: 0.8939\n",
            "Epoch 82/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2542 - recall: 0.8946 - val_loss: 0.2521 - val_recall: 0.8955\n",
            "Epoch 83/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2541 - recall: 0.8947 - val_loss: 0.2568 - val_recall: 0.8937\n",
            "Epoch 84/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2541 - recall: 0.8946 - val_loss: 0.2541 - val_recall: 0.8934\n",
            "Epoch 85/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2539 - recall: 0.8947 - val_loss: 0.2545 - val_recall: 0.8948\n",
            "Epoch 86/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2539 - recall: 0.8945 - val_loss: 0.2517 - val_recall: 0.8956\n",
            "Epoch 87/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2537 - recall: 0.8950 - val_loss: 0.2524 - val_recall: 0.8957\n",
            "Epoch 88/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2535 - recall: 0.8948 - val_loss: 0.2527 - val_recall: 0.8945\n",
            "Epoch 89/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2533 - recall: 0.8948 - val_loss: 0.2538 - val_recall: 0.8944\n",
            "Epoch 90/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2533 - recall: 0.8948 - val_loss: 0.2514 - val_recall: 0.8958\n",
            "Epoch 91/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2531 - recall: 0.8950 - val_loss: 0.2571 - val_recall: 0.8930\n",
            "Epoch 92/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2531 - recall: 0.8949 - val_loss: 0.2537 - val_recall: 0.8944\n",
            "Epoch 93/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2529 - recall: 0.8950 - val_loss: 0.2543 - val_recall: 0.8942\n",
            "Epoch 94/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2529 - recall: 0.8951 - val_loss: 0.2524 - val_recall: 0.8950\n",
            "Epoch 95/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2527 - recall: 0.8952 - val_loss: 0.2585 - val_recall: 0.8922\n",
            "Epoch 96/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2527 - recall: 0.8951 - val_loss: 0.2543 - val_recall: 0.8942\n",
            "Epoch 97/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2526 - recall: 0.8951 - val_loss: 0.2504 - val_recall: 0.8961\n",
            "Epoch 98/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2525 - recall: 0.8953 - val_loss: 0.2513 - val_recall: 0.8955\n",
            "Epoch 99/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2523 - recall: 0.8952 - val_loss: 0.2555 - val_recall: 0.8938\n",
            "Epoch 100/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2523 - recall: 0.8952 - val_loss: 0.2502 - val_recall: 0.8963\n",
            "Epoch 101/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2521 - recall: 0.8953 - val_loss: 0.2547 - val_recall: 0.8938\n",
            "Epoch 102/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2521 - recall: 0.8954 - val_loss: 0.2541 - val_recall: 0.8942\n",
            "Epoch 103/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2520 - recall: 0.8954 - val_loss: 0.2504 - val_recall: 0.8959\n",
            "Epoch 104/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2518 - recall: 0.8952 - val_loss: 0.2524 - val_recall: 0.8953\n",
            "Epoch 105/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2518 - recall: 0.8955 - val_loss: 0.2521 - val_recall: 0.8951\n",
            "Epoch 106/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2517 - recall: 0.8955 - val_loss: 0.2523 - val_recall: 0.8949\n",
            "Epoch 107/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2516 - recall: 0.8955 - val_loss: 0.2505 - val_recall: 0.8963\n",
            "Epoch 108/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2514 - recall: 0.8955 - val_loss: 0.2527 - val_recall: 0.8949\n",
            "Epoch 109/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2514 - recall: 0.8955 - val_loss: 0.2535 - val_recall: 0.8944\n",
            "Epoch 110/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2513 - recall: 0.8956 - val_loss: 0.2516 - val_recall: 0.8954\n",
            "Epoch 111/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2513 - recall: 0.8958 - val_loss: 0.2506 - val_recall: 0.8960\n",
            "Epoch 112/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2512 - recall: 0.8955 - val_loss: 0.2538 - val_recall: 0.8945\n",
            "Epoch 113/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2510 - recall: 0.8956 - val_loss: 0.2505 - val_recall: 0.8957\n",
            "Epoch 114/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2510 - recall: 0.8955 - val_loss: 0.2523 - val_recall: 0.8954\n",
            "Epoch 115/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2508 - recall: 0.8957 - val_loss: 0.2548 - val_recall: 0.8937\n",
            "Epoch 116/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2508 - recall: 0.8958 - val_loss: 0.2527 - val_recall: 0.8944\n",
            "Epoch 117/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2508 - recall: 0.8957 - val_loss: 0.2527 - val_recall: 0.8950\n",
            "Epoch 118/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2506 - recall: 0.8956 - val_loss: 0.2518 - val_recall: 0.8949\n",
            "Epoch 119/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2506 - recall: 0.8957 - val_loss: 0.2499 - val_recall: 0.8963\n",
            "Epoch 120/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2505 - recall: 0.8956 - val_loss: 0.2597 - val_recall: 0.8914\n",
            "Epoch 121/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2504 - recall: 0.8959 - val_loss: 0.2493 - val_recall: 0.8965\n",
            "Epoch 122/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2504 - recall: 0.8959 - val_loss: 0.2502 - val_recall: 0.8962\n",
            "Epoch 123/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2503 - recall: 0.8958 - val_loss: 0.2518 - val_recall: 0.8953\n",
            "Epoch 124/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2502 - recall: 0.8959 - val_loss: 0.2505 - val_recall: 0.8961\n",
            "Epoch 125/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2501 - recall: 0.8958 - val_loss: 0.2505 - val_recall: 0.8958\n",
            "Epoch 126/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2501 - recall: 0.8961 - val_loss: 0.2490 - val_recall: 0.8964\n",
            "Epoch 127/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2499 - recall: 0.8959 - val_loss: 0.2539 - val_recall: 0.8939\n",
            "Epoch 128/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2499 - recall: 0.8960 - val_loss: 0.2487 - val_recall: 0.8971\n",
            "Epoch 129/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2498 - recall: 0.8960 - val_loss: 0.2519 - val_recall: 0.8953\n",
            "Epoch 130/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2498 - recall: 0.8960 - val_loss: 0.2490 - val_recall: 0.8970\n",
            "Epoch 131/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2497 - recall: 0.8961 - val_loss: 0.2505 - val_recall: 0.8955\n",
            "Epoch 132/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2496 - recall: 0.8961 - val_loss: 0.2482 - val_recall: 0.8971\n",
            "Epoch 133/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2496 - recall: 0.8961 - val_loss: 0.2494 - val_recall: 0.8968\n",
            "Epoch 134/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2495 - recall: 0.8962 - val_loss: 0.2494 - val_recall: 0.8964\n",
            "Epoch 135/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2494 - recall: 0.8962 - val_loss: 0.2543 - val_recall: 0.8940\n",
            "Epoch 136/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2493 - recall: 0.8962 - val_loss: 0.2478 - val_recall: 0.8975\n",
            "Epoch 137/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2493 - recall: 0.8963 - val_loss: 0.2491 - val_recall: 0.8969\n",
            "Epoch 138/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2492 - recall: 0.8964 - val_loss: 0.2504 - val_recall: 0.8963\n",
            "Epoch 139/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2491 - recall: 0.8963 - val_loss: 0.2481 - val_recall: 0.8974\n",
            "Epoch 140/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2491 - recall: 0.8964 - val_loss: 0.2486 - val_recall: 0.8966\n",
            "Epoch 141/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2490 - recall: 0.8962 - val_loss: 0.2507 - val_recall: 0.8959\n",
            "Epoch 142/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2490 - recall: 0.8963 - val_loss: 0.2493 - val_recall: 0.8963\n",
            "Epoch 143/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2488 - recall: 0.8965 - val_loss: 0.2529 - val_recall: 0.8949\n",
            "Epoch 144/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2488 - recall: 0.8963 - val_loss: 0.2488 - val_recall: 0.8968\n",
            "Epoch 145/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2488 - recall: 0.8963 - val_loss: 0.2495 - val_recall: 0.8969\n",
            "Epoch 146/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2487 - recall: 0.8963 - val_loss: 0.2472 - val_recall: 0.8980\n",
            "Epoch 147/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2487 - recall: 0.8964 - val_loss: 0.2487 - val_recall: 0.8970\n",
            "Epoch 148/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2486 - recall: 0.8964 - val_loss: 0.2494 - val_recall: 0.8964\n",
            "Epoch 149/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2485 - recall: 0.8966 - val_loss: 0.2517 - val_recall: 0.8948\n",
            "Epoch 150/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2485 - recall: 0.8965 - val_loss: 0.2494 - val_recall: 0.8966\n",
            "Epoch 151/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2484 - recall: 0.8965 - val_loss: 0.2477 - val_recall: 0.8970\n",
            "Epoch 152/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2484 - recall: 0.8965 - val_loss: 0.2503 - val_recall: 0.8958\n",
            "Epoch 153/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2483 - recall: 0.8965 - val_loss: 0.2505 - val_recall: 0.8959\n",
            "Epoch 154/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2483 - recall: 0.8964 - val_loss: 0.2487 - val_recall: 0.8971\n",
            "Epoch 155/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2482 - recall: 0.8965 - val_loss: 0.2506 - val_recall: 0.8964\n",
            "Epoch 156/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2482 - recall: 0.8967 - val_loss: 0.2568 - val_recall: 0.8930\n",
            "Epoch 157/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2481 - recall: 0.8967 - val_loss: 0.2470 - val_recall: 0.8976\n",
            "Epoch 158/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2480 - recall: 0.8967 - val_loss: 0.2480 - val_recall: 0.8968\n",
            "Epoch 159/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2480 - recall: 0.8966 - val_loss: 0.2484 - val_recall: 0.8971\n",
            "Epoch 160/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2480 - recall: 0.8966 - val_loss: 0.2493 - val_recall: 0.8969\n",
            "Epoch 161/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2479 - recall: 0.8965 - val_loss: 0.2476 - val_recall: 0.8977\n",
            "Epoch 162/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2478 - recall: 0.8968 - val_loss: 0.2473 - val_recall: 0.8969\n",
            "Epoch 163/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2478 - recall: 0.8966 - val_loss: 0.2482 - val_recall: 0.8975\n",
            "Epoch 164/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2478 - recall: 0.8964 - val_loss: 0.2488 - val_recall: 0.8967\n",
            "Epoch 165/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2477 - recall: 0.8967 - val_loss: 0.2485 - val_recall: 0.8968\n",
            "Epoch 166/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2476 - recall: 0.8967 - val_loss: 0.2483 - val_recall: 0.8969\n",
            "Epoch 167/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2476 - recall: 0.8968 - val_loss: 0.2520 - val_recall: 0.8947\n",
            "Epoch 168/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2476 - recall: 0.8966 - val_loss: 0.2536 - val_recall: 0.8942\n",
            "Epoch 169/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2475 - recall: 0.8968 - val_loss: 0.2531 - val_recall: 0.8947\n",
            "Epoch 170/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2475 - recall: 0.8970 - val_loss: 0.2491 - val_recall: 0.8963\n",
            "Epoch 171/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2474 - recall: 0.8970 - val_loss: 0.2519 - val_recall: 0.8949\n",
            "Epoch 172/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2474 - recall: 0.8968 - val_loss: 0.2465 - val_recall: 0.8978\n",
            "Epoch 173/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2473 - recall: 0.8968 - val_loss: 0.2468 - val_recall: 0.8979\n",
            "Epoch 174/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2473 - recall: 0.8968 - val_loss: 0.2473 - val_recall: 0.8976\n",
            "Epoch 175/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2472 - recall: 0.8969 - val_loss: 0.2539 - val_recall: 0.8943\n",
            "Epoch 176/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2471 - recall: 0.8970 - val_loss: 0.2473 - val_recall: 0.8974\n",
            "Epoch 177/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2471 - recall: 0.8969 - val_loss: 0.2479 - val_recall: 0.8973\n",
            "Epoch 178/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2471 - recall: 0.8968 - val_loss: 0.2469 - val_recall: 0.8975\n",
            "Epoch 179/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2470 - recall: 0.8970 - val_loss: 0.2488 - val_recall: 0.8962\n",
            "Epoch 180/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2470 - recall: 0.8969 - val_loss: 0.2477 - val_recall: 0.8970\n",
            "Epoch 181/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2469 - recall: 0.8969 - val_loss: 0.2481 - val_recall: 0.8973\n",
            "Epoch 182/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2469 - recall: 0.8970 - val_loss: 0.2470 - val_recall: 0.8975\n",
            "Epoch 183/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2468 - recall: 0.8970 - val_loss: 0.2475 - val_recall: 0.8973\n",
            "Epoch 184/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2468 - recall: 0.8971 - val_loss: 0.2464 - val_recall: 0.8985\n",
            "Epoch 185/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2467 - recall: 0.8970 - val_loss: 0.2480 - val_recall: 0.8974\n",
            "Epoch 186/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2466 - recall: 0.8970 - val_loss: 0.2512 - val_recall: 0.8955\n",
            "Epoch 187/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2467 - recall: 0.8971 - val_loss: 0.2478 - val_recall: 0.8971\n",
            "Epoch 188/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2466 - recall: 0.8972 - val_loss: 0.2454 - val_recall: 0.8985\n",
            "Epoch 189/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2465 - recall: 0.8971 - val_loss: 0.2457 - val_recall: 0.8983\n",
            "Epoch 190/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2466 - recall: 0.8971 - val_loss: 0.2456 - val_recall: 0.8982\n",
            "Epoch 191/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2464 - recall: 0.8970 - val_loss: 0.2491 - val_recall: 0.8961\n",
            "Epoch 192/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2464 - recall: 0.8970 - val_loss: 0.2464 - val_recall: 0.8985\n",
            "Epoch 193/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2465 - recall: 0.8973 - val_loss: 0.2452 - val_recall: 0.8983\n",
            "Epoch 194/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2463 - recall: 0.8972 - val_loss: 0.2463 - val_recall: 0.8986\n",
            "Epoch 195/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2463 - recall: 0.8971 - val_loss: 0.2486 - val_recall: 0.8972\n",
            "Epoch 196/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2462 - recall: 0.8974 - val_loss: 0.2508 - val_recall: 0.8955\n",
            "Epoch 197/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2462 - recall: 0.8972 - val_loss: 0.2483 - val_recall: 0.8970\n",
            "Epoch 198/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2461 - recall: 0.8973 - val_loss: 0.2511 - val_recall: 0.8954\n",
            "Epoch 199/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2461 - recall: 0.8972 - val_loss: 0.2461 - val_recall: 0.8986\n",
            "Epoch 200/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2461 - recall: 0.8972 - val_loss: 0.2455 - val_recall: 0.8985\n",
            "Epoch 201/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2461 - recall: 0.8974 - val_loss: 0.2454 - val_recall: 0.8988\n",
            "Epoch 202/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2460 - recall: 0.8975 - val_loss: 0.2486 - val_recall: 0.8970\n",
            "Epoch 203/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2459 - recall: 0.8973 - val_loss: 0.2464 - val_recall: 0.8976\n",
            "Epoch 204/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2459 - recall: 0.8973 - val_loss: 0.2452 - val_recall: 0.8983\n",
            "Epoch 205/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2459 - recall: 0.8974 - val_loss: 0.2475 - val_recall: 0.8974\n",
            "Epoch 206/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2459 - recall: 0.8974 - val_loss: 0.2460 - val_recall: 0.8980\n",
            "Epoch 207/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2458 - recall: 0.8973 - val_loss: 0.2485 - val_recall: 0.8968\n",
            "Epoch 208/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2458 - recall: 0.8974 - val_loss: 0.2462 - val_recall: 0.8984\n",
            "Epoch 209/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2457 - recall: 0.8974 - val_loss: 0.2490 - val_recall: 0.8965\n",
            "Epoch 210/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2458 - recall: 0.8974 - val_loss: 0.2451 - val_recall: 0.8985\n",
            "Epoch 211/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2457 - recall: 0.8975 - val_loss: 0.2452 - val_recall: 0.8987\n",
            "Epoch 212/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2457 - recall: 0.8975 - val_loss: 0.2464 - val_recall: 0.8976\n",
            "Epoch 213/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2456 - recall: 0.8973 - val_loss: 0.2454 - val_recall: 0.8982\n",
            "Epoch 214/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2455 - recall: 0.8976 - val_loss: 0.2472 - val_recall: 0.8981\n",
            "Epoch 215/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2455 - recall: 0.8976 - val_loss: 0.2474 - val_recall: 0.8974\n",
            "Epoch 216/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2454 - recall: 0.8976 - val_loss: 0.2453 - val_recall: 0.8980\n",
            "Epoch 217/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2454 - recall: 0.8975 - val_loss: 0.2451 - val_recall: 0.8989\n",
            "Epoch 218/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2454 - recall: 0.8975 - val_loss: 0.2458 - val_recall: 0.8981\n",
            "Epoch 219/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2454 - recall: 0.8976 - val_loss: 0.2486 - val_recall: 0.8968\n",
            "Epoch 220/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2453 - recall: 0.8975 - val_loss: 0.2463 - val_recall: 0.8972\n",
            "Epoch 221/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2452 - recall: 0.8977 - val_loss: 0.2458 - val_recall: 0.8982\n",
            "Epoch 222/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2451 - recall: 0.8976 - val_loss: 0.2461 - val_recall: 0.8976\n",
            "Epoch 223/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2452 - recall: 0.8977 - val_loss: 0.2501 - val_recall: 0.8959\n",
            "Epoch 224/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2452 - recall: 0.8977 - val_loss: 0.2455 - val_recall: 0.8984\n",
            "Epoch 225/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2452 - recall: 0.8977 - val_loss: 0.2454 - val_recall: 0.8987\n",
            "Epoch 226/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2451 - recall: 0.8976 - val_loss: 0.2496 - val_recall: 0.8960\n",
            "Epoch 227/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2451 - recall: 0.8976 - val_loss: 0.2478 - val_recall: 0.8972\n",
            "Epoch 228/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2451 - recall: 0.8978 - val_loss: 0.2461 - val_recall: 0.8979\n",
            "Epoch 229/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2450 - recall: 0.8978 - val_loss: 0.2482 - val_recall: 0.8972\n",
            "Epoch 230/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2450 - recall: 0.8977 - val_loss: 0.2485 - val_recall: 0.8967\n",
            "Epoch 231/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2449 - recall: 0.8978 - val_loss: 0.2468 - val_recall: 0.8972\n",
            "Epoch 232/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2449 - recall: 0.8980 - val_loss: 0.2451 - val_recall: 0.8983\n",
            "Epoch 233/300\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2448 - recall: 0.8979 - val_loss: 0.2458 - val_recall: 0.8983\n",
            "Epoch 234/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2448 - recall: 0.8978 - val_loss: 0.2470 - val_recall: 0.8977\n",
            "Epoch 235/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2448 - recall: 0.8979 - val_loss: 0.2491 - val_recall: 0.8966\n",
            "Epoch 236/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2447 - recall: 0.8978 - val_loss: 0.2484 - val_recall: 0.8971\n",
            "Epoch 237/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2447 - recall: 0.8977 - val_loss: 0.2448 - val_recall: 0.8987\n",
            "Epoch 238/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2447 - recall: 0.8980 - val_loss: 0.2455 - val_recall: 0.8983\n",
            "Epoch 239/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2447 - recall: 0.8980 - val_loss: 0.2446 - val_recall: 0.8982\n",
            "Epoch 240/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2446 - recall: 0.8980 - val_loss: 0.2447 - val_recall: 0.8987\n",
            "Epoch 241/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2446 - recall: 0.8980 - val_loss: 0.2460 - val_recall: 0.8980\n",
            "Epoch 242/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2445 - recall: 0.8980 - val_loss: 0.2483 - val_recall: 0.8972\n",
            "Epoch 243/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2446 - recall: 0.8979 - val_loss: 0.2448 - val_recall: 0.8985\n",
            "Epoch 244/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2445 - recall: 0.8981 - val_loss: 0.2447 - val_recall: 0.8986\n",
            "Epoch 245/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2444 - recall: 0.8980 - val_loss: 0.2468 - val_recall: 0.8973\n",
            "Epoch 246/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2444 - recall: 0.8981 - val_loss: 0.2455 - val_recall: 0.8979\n",
            "Epoch 247/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2444 - recall: 0.8980 - val_loss: 0.2468 - val_recall: 0.8979\n",
            "Epoch 248/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2443 - recall: 0.8982 - val_loss: 0.2444 - val_recall: 0.8987\n",
            "Epoch 249/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2443 - recall: 0.8982 - val_loss: 0.2453 - val_recall: 0.8979\n",
            "Epoch 250/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2443 - recall: 0.8981 - val_loss: 0.2464 - val_recall: 0.8981\n",
            "Epoch 251/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2442 - recall: 0.8982 - val_loss: 0.2463 - val_recall: 0.8978\n",
            "Epoch 252/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2442 - recall: 0.8981 - val_loss: 0.2463 - val_recall: 0.8977\n",
            "Epoch 253/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2442 - recall: 0.8981 - val_loss: 0.2439 - val_recall: 0.8986\n",
            "Epoch 254/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2442 - recall: 0.8983 - val_loss: 0.2451 - val_recall: 0.8979\n",
            "Epoch 255/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2441 - recall: 0.8982 - val_loss: 0.2460 - val_recall: 0.8979\n",
            "Epoch 256/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2441 - recall: 0.8982 - val_loss: 0.2463 - val_recall: 0.8983\n",
            "Epoch 257/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2441 - recall: 0.8981 - val_loss: 0.2447 - val_recall: 0.8981\n",
            "Epoch 258/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2440 - recall: 0.8982 - val_loss: 0.2450 - val_recall: 0.8985\n",
            "Epoch 259/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2440 - recall: 0.8981 - val_loss: 0.2463 - val_recall: 0.8978\n",
            "Epoch 260/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2440 - recall: 0.8983 - val_loss: 0.2466 - val_recall: 0.8975\n",
            "Epoch 261/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2440 - recall: 0.8981 - val_loss: 0.2444 - val_recall: 0.8991\n",
            "Epoch 262/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2439 - recall: 0.8982 - val_loss: 0.2489 - val_recall: 0.8966\n",
            "Epoch 263/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2439 - recall: 0.8982 - val_loss: 0.2451 - val_recall: 0.8982\n",
            "Epoch 264/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2439 - recall: 0.8984 - val_loss: 0.2457 - val_recall: 0.8978\n",
            "Epoch 265/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2438 - recall: 0.8983 - val_loss: 0.2457 - val_recall: 0.8979\n",
            "Epoch 266/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2438 - recall: 0.8980 - val_loss: 0.2443 - val_recall: 0.8987\n",
            "Epoch 267/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2438 - recall: 0.8984 - val_loss: 0.2442 - val_recall: 0.8990\n",
            "Epoch 268/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2437 - recall: 0.8983 - val_loss: 0.2478 - val_recall: 0.8971\n",
            "Epoch 269/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2437 - recall: 0.8984 - val_loss: 0.2467 - val_recall: 0.8976\n",
            "Epoch 270/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2437 - recall: 0.8985 - val_loss: 0.2448 - val_recall: 0.8984\n",
            "Epoch 271/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2437 - recall: 0.8984 - val_loss: 0.2437 - val_recall: 0.8988\n",
            "Epoch 272/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2436 - recall: 0.8983 - val_loss: 0.2474 - val_recall: 0.8971\n",
            "Epoch 273/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2436 - recall: 0.8986 - val_loss: 0.2437 - val_recall: 0.8986\n",
            "Epoch 274/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2435 - recall: 0.8984 - val_loss: 0.2482 - val_recall: 0.8964\n",
            "Epoch 275/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2435 - recall: 0.8985 - val_loss: 0.2446 - val_recall: 0.8984\n",
            "Epoch 276/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2436 - recall: 0.8985 - val_loss: 0.2445 - val_recall: 0.8982\n",
            "Epoch 277/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2436 - recall: 0.8983 - val_loss: 0.2435 - val_recall: 0.8990\n",
            "Epoch 278/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2435 - recall: 0.8984 - val_loss: 0.2463 - val_recall: 0.8978\n",
            "Epoch 279/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2435 - recall: 0.8984 - val_loss: 0.2464 - val_recall: 0.8976\n",
            "Epoch 280/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2434 - recall: 0.8985 - val_loss: 0.2522 - val_recall: 0.8950\n",
            "Epoch 281/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2434 - recall: 0.8984 - val_loss: 0.2462 - val_recall: 0.8982\n",
            "Epoch 282/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2434 - recall: 0.8985 - val_loss: 0.2439 - val_recall: 0.8987\n",
            "Epoch 283/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2434 - recall: 0.8984 - val_loss: 0.2520 - val_recall: 0.8949\n",
            "Epoch 284/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2433 - recall: 0.8986 - val_loss: 0.2454 - val_recall: 0.8979\n",
            "Epoch 285/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2433 - recall: 0.8985 - val_loss: 0.2448 - val_recall: 0.8987\n",
            "Epoch 286/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2432 - recall: 0.8984 - val_loss: 0.2443 - val_recall: 0.8984\n",
            "Epoch 287/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2433 - recall: 0.8987 - val_loss: 0.2446 - val_recall: 0.8992\n",
            "Epoch 288/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2432 - recall: 0.8985 - val_loss: 0.2439 - val_recall: 0.8984\n",
            "Epoch 289/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2432 - recall: 0.8986 - val_loss: 0.2452 - val_recall: 0.8982\n",
            "Epoch 290/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2432 - recall: 0.8986 - val_loss: 0.2459 - val_recall: 0.8979\n",
            "Epoch 291/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2431 - recall: 0.8986 - val_loss: 0.2488 - val_recall: 0.8968\n",
            "Epoch 292/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2431 - recall: 0.8986 - val_loss: 0.2463 - val_recall: 0.8977\n",
            "Epoch 293/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2431 - recall: 0.8986 - val_loss: 0.2435 - val_recall: 0.8992\n",
            "Epoch 294/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2430 - recall: 0.8987 - val_loss: 0.2443 - val_recall: 0.8986\n",
            "Epoch 295/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2430 - recall: 0.8987 - val_loss: 0.2429 - val_recall: 0.8992\n",
            "Epoch 296/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2430 - recall: 0.8986 - val_loss: 0.2444 - val_recall: 0.8985\n",
            "Epoch 297/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2430 - recall: 0.8986 - val_loss: 0.2436 - val_recall: 0.8992\n",
            "Epoch 298/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2429 - recall: 0.8987 - val_loss: 0.2437 - val_recall: 0.8986\n",
            "Epoch 299/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2429 - recall: 0.8987 - val_loss: 0.2452 - val_recall: 0.8984\n",
            "Epoch 300/300\n",
            "312/312 [==============================] - 1s 3ms/step - loss: 0.2428 - recall: 0.8987 - val_loss: 0.2435 - val_recall: 0.8992\n"
          ]
        }
      ],
      "source": [
        "print('\\nFitting DNN (Detection Module):\\n')\n",
        "batch_size1 = 1800\n",
        "history_detection = model_detection.fit(X_trn_detection, t_trn_detection, epochs=300,\n",
        "                                validation_split=.2, batch_size = batch_size1,\n",
        "                                callbacks=callbacks_list, verbose=1)"
      ],
      "id": "n9ERTXMyPtft"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9MP-s6OIPtft",
        "outputId": "8fa4407b-5da6-47cd-9689-ccfa2d048a88"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x194b5f88940>"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the variation of loss function on both training and validation set: \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_loss = history_detection.history[\"val_loss\"]\n",
        "loss = history_detection.history[\"loss\"]\n",
        "\n",
        "epochs = range(1, 301)\n",
        "plt.plot(epochs, val_loss[:], \"r-\",\n",
        "label=\"Validation Loss\")\n",
        "plt.plot(epochs, loss[:], \"b-\",\n",
        "label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "id": "9MP-s6OIPtft"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CUA1LS6wPtft"
      },
      "outputs": [],
      "source": [
        "# Testing the trained network over the testset.\n",
        "\n",
        "predictions_label = model_detection.predict(X_tst_detection)\n",
        "\n",
        "y_pred = np.zeros([len(X_tst_detection),1])\n",
        "for i in range(len(X_tst_detection)):\n",
        "    y_pred[i,0] = np.argmax(predictions_label[i])\n",
        "    \n"
      ],
      "id": "CUA1LS6wPtft"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aSRmt0RQPtfu"
      },
      "source": [
        "### Metrics"
      ],
      "id": "aSRmt0RQPtfu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fnIabh8yPtfu",
        "outputId": "3354bff8-3788-4876-e7db-f6a8473c417d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " For Rainfall Detection Over Coast:\n",
            "\n",
            "Precision:  0.9229271348230456\n",
            "Accuracy:  0.9393267166995578\n",
            "Recall (TPR):  0.9608171134517515\n",
            "False Alarm (FPR):  0.08286847923163643\n",
            "\n",
            "F1 Score:  0.94149106113434\n",
            "----------------------------\n",
            "\n",
            " For Snwofall Detection Over Coast:\n",
            "\n",
            "Precision:  0.9577382954649705\n",
            "Accuracy:  0.9393267166995578\n",
            "Recall (TPR):  0.9171278807578552\n",
            "False Alarm (FPR):  0.039181220231344974\n",
            "\n",
            "F1 Score:  0.9369932685115931\n",
            "----------------------------\n",
            "\n",
            " For Model Detection Over Coast:\n",
            "\n",
            "Precision:  0.939312311836476\n",
            "Recall (TPR):  0.939312311836476\n",
            "\n",
            "F1 Score:  0.939312311836476\n"
          ]
        }
      ],
      "source": [
        "### Detection Module\n",
        "\n",
        "n_cc=1\n",
        "n_cs=1\n",
        "n_cr=1\n",
        "n_sc=1\n",
        "n_ss=1\n",
        "n_sr=1\n",
        "n_rc=1\n",
        "n_rs=1\n",
        "n_rr=1\n",
        "\n",
        "precip_c= 3\n",
        "precip_r= 2\n",
        "precip_s= 1\n",
        "\n",
        "for i in range(len(X_tst_detection)):\n",
        "    label_predict = y_pred[i]\n",
        "    label_actual = t_test[i]\n",
        "    if label_predict==precip_c and label_actual==precip_c:\n",
        "        n_cc+=1\n",
        "    if label_predict==precip_s and label_actual==precip_s:\n",
        "        n_ss+=1\n",
        "    if label_predict==precip_r and label_actual==precip_r:\n",
        "        n_rr+=1 \n",
        "    if label_predict==precip_c and label_actual==precip_s:\n",
        "        n_cs+=1\n",
        "    if label_predict==precip_c and label_actual==precip_r:\n",
        "        n_cr+=1\n",
        "    if label_predict==precip_s and label_actual==precip_c:\n",
        "        n_sc+=1\n",
        "    if label_predict==precip_s and label_actual==precip_r:\n",
        "        n_sr+=1  \n",
        "    if label_predict==precip_r and label_actual==precip_c:\n",
        "        n_rc+=1\n",
        "    if label_predict==precip_r and label_actual==precip_s:\n",
        "        n_rs+=1        \n",
        "        \n",
        "#Snow\n",
        "TP_s = n_ss\n",
        "TN_s = n_cc+n_cr+n_rc+n_rr\n",
        "FP_s = n_sc+n_sr\n",
        "FN_s = n_cs+n_rs\n",
        "\n",
        "precision_s = TP_s/(TP_s+FP_s)\n",
        "acc_s = (TP_s+TN_s)/(TP_s+TN_s+FP_s+FN_s)\n",
        "recall_s = TP_s/(TP_s+FN_s)\n",
        "f1_score_s = (2*precision_s*recall_s)/(precision_s+recall_s)\n",
        "FPR_s = FP_s/(FP_s+TN_s)\n",
        "\n",
        "#Rain\n",
        "TP_r = n_rr\n",
        "TN_r = n_cc+n_cs+n_sc+n_ss\n",
        "FP_r = n_rc+n_rs\n",
        "FN_r = n_cr+n_sr\n",
        "\n",
        "precision_r = TP_r/(TP_r+FP_r)\n",
        "acc_r = (TP_r+TN_r)/(TP_r+TN_r+FP_r+FN_r)\n",
        "recall_r = TP_r/(TP_r+FN_r)\n",
        "f1_score_r = (2*precision_r*recall_r)/(precision_r+recall_r)\n",
        "FPR_r = FP_r/(FP_r+TN_r) \n",
        "\n",
        "print('\\n For Rainfall Detection Over Coast:\\n')\n",
        "print('Precision: ',precision_r)\n",
        "print('Accuracy: ',acc_r)\n",
        "print('Recall (TPR): ',recall_r)\n",
        "print('False Alarm (FPR): ',FPR_r)\n",
        "print('\\nF1 Score: ',f1_score_r)\n",
        "\n",
        "print('----------------------------')\n",
        "print('\\n For Snwofall Detection Over Coast:\\n')\n",
        "print('Precision: ',precision_s)\n",
        "print('Accuracy: ',acc_s)\n",
        "print('Recall (TPR): ',recall_s)\n",
        "print('False Alarm (FPR): ',FPR_s)\n",
        "print('\\nF1 Score: ',f1_score_s)\n",
        "\n",
        "#Model\n",
        "TP = n_cc+n_ss+n_rr\n",
        "FP = n_cs+n_cr+n_sc+n_sr+n_rc+n_rs\n",
        "FN = n_sc+n_rc+n_cs+n_rs+n_cr+n_sr\n",
        "\n",
        "precision = TP/(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "f1_score = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "print('----------------------------')\n",
        "print('\\n For Model Detection Over Coast:\\n')\n",
        "print('Precision: ',precision)\n",
        "print('Recall (TPR): ',recall)\n",
        "print('\\nF1 Score: ',f1_score)"
      ],
      "id": "fnIabh8yPtfu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w4ipvtUdPtfu",
        "outputId": "8572eeb8-ba08-4bd4-ae59-3b04eb7205cb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "167/167 [==============================] - 0s 704us/step - loss: 0.2436 - recall: 0.8984\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.24363692104816437, 0.8983533382415771]"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_detection.evaluate(X_tst_detection, t_tst_detection, batch_size = batch_size1)"
      ],
      "id": "w4ipvtUdPtfu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5A3VeLBsPtfu"
      },
      "source": [
        "## **2.2 - Estimation networks (e-DNN)**"
      ],
      "id": "5A3VeLBsPtfu"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wfTOnmJkPtfu"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return backend.sqrt(backend.mean(backend.square(y_pred-y_true)))\n",
        "    \n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "        return backend.mean(backend.abs(y_pred-y_true))        "
      ],
      "id": "wfTOnmJkPtfu"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hN4pntCPtfv"
      },
      "source": [
        "### **2.2.1 Snowfall retrieval**"
      ],
      "id": "2hN4pntCPtfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "araEu_SkPtfv"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "hidden_units = 90\n",
        "dropout = 0\n",
        "\n",
        "# COAST\n",
        "model_retrieval_snow = Sequential()\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(hidden_units))\n",
        "model_retrieval_snow.add(Activation('relu'))\n",
        "model_retrieval_snow.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_snow.add(Dense(1))\n",
        "model_retrieval_snow.add(Activation('relu'))"
      ],
      "id": "araEu_SkPtfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FgDU7dl7Ptfv"
      },
      "outputs": [],
      "source": [
        "model_retrieval_snow.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss = root_mean_squared_error,\n",
        "              metrics= mean_absolute_error)"
      ],
      "id": "FgDU7dl7Ptfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TNnpbV4hPtfv"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=25,),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint_path.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    )    \n",
        "]"
      ],
      "id": "TNnpbV4hPtfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "shnu2-AiPtfv",
        "outputId": "91f9f681-0385-450b-bf65-a636445cac4f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting DNN (Retrieval Module - Snow):\n",
            "\n",
            "Epoch 1/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 1.0229 - mean_absolute_error: 0.6591 - val_loss: 0.8711 - val_mean_absolute_error: 0.4885\n",
            "Epoch 2/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.7740 - mean_absolute_error: 0.4171 - val_loss: 0.7115 - val_mean_absolute_error: 0.3874\n",
            "Epoch 3/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.7111 - mean_absolute_error: 0.3866 - val_loss: 0.6910 - val_mean_absolute_error: 0.3763\n",
            "Epoch 4/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6956 - mean_absolute_error: 0.3752 - val_loss: 0.6757 - val_mean_absolute_error: 0.3644\n",
            "Epoch 5/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6826 - mean_absolute_error: 0.3664 - val_loss: 0.6626 - val_mean_absolute_error: 0.3565\n",
            "Epoch 6/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6707 - mean_absolute_error: 0.3590 - val_loss: 0.6507 - val_mean_absolute_error: 0.3485\n",
            "Epoch 7/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6604 - mean_absolute_error: 0.3527 - val_loss: 0.6399 - val_mean_absolute_error: 0.3450\n",
            "Epoch 8/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6511 - mean_absolute_error: 0.3470 - val_loss: 0.6298 - val_mean_absolute_error: 0.3373\n",
            "Epoch 9/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6429 - mean_absolute_error: 0.3406 - val_loss: 0.6212 - val_mean_absolute_error: 0.3308\n",
            "Epoch 10/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6359 - mean_absolute_error: 0.3353 - val_loss: 0.6140 - val_mean_absolute_error: 0.3254\n",
            "Epoch 11/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6314 - mean_absolute_error: 0.3312 - val_loss: 0.6083 - val_mean_absolute_error: 0.3203\n",
            "Epoch 12/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6280 - mean_absolute_error: 0.3274 - val_loss: 0.6038 - val_mean_absolute_error: 0.3168\n",
            "Epoch 13/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6238 - mean_absolute_error: 0.3246 - val_loss: 0.6006 - val_mean_absolute_error: 0.3152\n",
            "Epoch 14/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6220 - mean_absolute_error: 0.3228 - val_loss: 0.5981 - val_mean_absolute_error: 0.3142\n",
            "Epoch 15/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6194 - mean_absolute_error: 0.3207 - val_loss: 0.5964 - val_mean_absolute_error: 0.3133\n",
            "Epoch 16/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6182 - mean_absolute_error: 0.3194 - val_loss: 0.5948 - val_mean_absolute_error: 0.3078\n",
            "Epoch 17/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6168 - mean_absolute_error: 0.3178 - val_loss: 0.5942 - val_mean_absolute_error: 0.3047\n",
            "Epoch 18/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6159 - mean_absolute_error: 0.3166 - val_loss: 0.5927 - val_mean_absolute_error: 0.3075\n",
            "Epoch 19/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6156 - mean_absolute_error: 0.3161 - val_loss: 0.5920 - val_mean_absolute_error: 0.3074\n",
            "Epoch 20/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6154 - mean_absolute_error: 0.3154 - val_loss: 0.5913 - val_mean_absolute_error: 0.3065\n",
            "Epoch 21/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6146 - mean_absolute_error: 0.3147 - val_loss: 0.5908 - val_mean_absolute_error: 0.3077\n",
            "Epoch 22/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6139 - mean_absolute_error: 0.3138 - val_loss: 0.5902 - val_mean_absolute_error: 0.3049\n",
            "Epoch 23/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6140 - mean_absolute_error: 0.3131 - val_loss: 0.5897 - val_mean_absolute_error: 0.3041\n",
            "Epoch 24/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.6124 - mean_absolute_error: 0.3125 - val_loss: 0.5893 - val_mean_absolute_error: 0.3043\n",
            "Epoch 25/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6105 - mean_absolute_error: 0.3119 - val_loss: 0.5888 - val_mean_absolute_error: 0.3019\n",
            "Epoch 26/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.6112 - mean_absolute_error: 0.3112 - val_loss: 0.5886 - val_mean_absolute_error: 0.3027\n",
            "Epoch 27/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6109 - mean_absolute_error: 0.3114 - val_loss: 0.5882 - val_mean_absolute_error: 0.3036\n",
            "Epoch 28/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 0.6101 - mean_absolute_error: 0.3108 - val_loss: 0.5879 - val_mean_absolute_error: 0.3017\n",
            "Epoch 29/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6098 - mean_absolute_error: 0.3101 - val_loss: 0.5881 - val_mean_absolute_error: 0.2984\n",
            "Epoch 30/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6096 - mean_absolute_error: 0.3098 - val_loss: 0.5873 - val_mean_absolute_error: 0.3004\n",
            "Epoch 31/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6098 - mean_absolute_error: 0.3094 - val_loss: 0.5871 - val_mean_absolute_error: 0.3018\n",
            "Epoch 32/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6087 - mean_absolute_error: 0.3096 - val_loss: 0.5869 - val_mean_absolute_error: 0.2989\n",
            "Epoch 33/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6090 - mean_absolute_error: 0.3086 - val_loss: 0.5868 - val_mean_absolute_error: 0.3019\n",
            "Epoch 34/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6084 - mean_absolute_error: 0.3087 - val_loss: 0.5864 - val_mean_absolute_error: 0.3003\n",
            "Epoch 35/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6080 - mean_absolute_error: 0.3083 - val_loss: 0.5866 - val_mean_absolute_error: 0.3030\n",
            "Epoch 36/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6085 - mean_absolute_error: 0.3078 - val_loss: 0.5861 - val_mean_absolute_error: 0.2980\n",
            "Epoch 37/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6079 - mean_absolute_error: 0.3078 - val_loss: 0.5860 - val_mean_absolute_error: 0.3008\n",
            "Epoch 38/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6086 - mean_absolute_error: 0.3074 - val_loss: 0.5859 - val_mean_absolute_error: 0.3006\n",
            "Epoch 39/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6081 - mean_absolute_error: 0.3073 - val_loss: 0.5857 - val_mean_absolute_error: 0.3000\n",
            "Epoch 40/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6066 - mean_absolute_error: 0.3071 - val_loss: 0.5857 - val_mean_absolute_error: 0.3011\n",
            "Epoch 41/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6053 - mean_absolute_error: 0.3069 - val_loss: 0.5853 - val_mean_absolute_error: 0.2989\n",
            "Epoch 42/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6054 - mean_absolute_error: 0.3067 - val_loss: 0.5851 - val_mean_absolute_error: 0.2981\n",
            "Epoch 43/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6066 - mean_absolute_error: 0.3067 - val_loss: 0.5850 - val_mean_absolute_error: 0.2980\n",
            "Epoch 44/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6059 - mean_absolute_error: 0.3062 - val_loss: 0.5849 - val_mean_absolute_error: 0.2981\n",
            "Epoch 45/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6058 - mean_absolute_error: 0.3063 - val_loss: 0.5847 - val_mean_absolute_error: 0.2976\n",
            "Epoch 46/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6054 - mean_absolute_error: 0.3055 - val_loss: 0.5847 - val_mean_absolute_error: 0.2964\n",
            "Epoch 47/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6056 - mean_absolute_error: 0.3053 - val_loss: 0.5845 - val_mean_absolute_error: 0.2983\n",
            "Epoch 48/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6058 - mean_absolute_error: 0.3055 - val_loss: 0.5844 - val_mean_absolute_error: 0.2953\n",
            "Epoch 49/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6048 - mean_absolute_error: 0.3051 - val_loss: 0.5843 - val_mean_absolute_error: 0.2980\n",
            "Epoch 50/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6048 - mean_absolute_error: 0.3055 - val_loss: 0.5841 - val_mean_absolute_error: 0.2974\n",
            "Epoch 51/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6051 - mean_absolute_error: 0.3047 - val_loss: 0.5847 - val_mean_absolute_error: 0.2926\n",
            "Epoch 52/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6044 - mean_absolute_error: 0.3047 - val_loss: 0.5843 - val_mean_absolute_error: 0.2936\n",
            "Epoch 53/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6051 - mean_absolute_error: 0.3045 - val_loss: 0.5838 - val_mean_absolute_error: 0.2956\n",
            "Epoch 54/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6041 - mean_absolute_error: 0.3041 - val_loss: 0.5837 - val_mean_absolute_error: 0.2942\n",
            "Epoch 55/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6048 - mean_absolute_error: 0.3038 - val_loss: 0.5836 - val_mean_absolute_error: 0.2944\n",
            "Epoch 56/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6032 - mean_absolute_error: 0.3037 - val_loss: 0.5837 - val_mean_absolute_error: 0.2940\n",
            "Epoch 57/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6050 - mean_absolute_error: 0.3035 - val_loss: 0.5836 - val_mean_absolute_error: 0.2969\n",
            "Epoch 58/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6041 - mean_absolute_error: 0.3041 - val_loss: 0.5836 - val_mean_absolute_error: 0.2980\n",
            "Epoch 59/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6029 - mean_absolute_error: 0.3039 - val_loss: 0.5834 - val_mean_absolute_error: 0.2940\n",
            "Epoch 60/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6039 - mean_absolute_error: 0.3033 - val_loss: 0.5832 - val_mean_absolute_error: 0.2937\n",
            "Epoch 61/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6027 - mean_absolute_error: 0.3030 - val_loss: 0.5832 - val_mean_absolute_error: 0.2943\n",
            "Epoch 62/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6039 - mean_absolute_error: 0.3032 - val_loss: 0.5832 - val_mean_absolute_error: 0.2948\n",
            "Epoch 63/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6036 - mean_absolute_error: 0.3030 - val_loss: 0.5832 - val_mean_absolute_error: 0.2959\n",
            "Epoch 64/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6022 - mean_absolute_error: 0.3031 - val_loss: 0.5831 - val_mean_absolute_error: 0.2952\n",
            "Epoch 65/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6030 - mean_absolute_error: 0.3029 - val_loss: 0.5830 - val_mean_absolute_error: 0.2949\n",
            "Epoch 66/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6014 - mean_absolute_error: 0.3026 - val_loss: 0.5830 - val_mean_absolute_error: 0.2947\n",
            "Epoch 67/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6032 - mean_absolute_error: 0.3026 - val_loss: 0.5832 - val_mean_absolute_error: 0.2974\n",
            "Epoch 68/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6029 - mean_absolute_error: 0.3028 - val_loss: 0.5831 - val_mean_absolute_error: 0.2926\n",
            "Epoch 69/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6019 - mean_absolute_error: 0.3020 - val_loss: 0.5830 - val_mean_absolute_error: 0.2962\n",
            "Epoch 70/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6017 - mean_absolute_error: 0.3024 - val_loss: 0.5830 - val_mean_absolute_error: 0.2924\n",
            "Epoch 71/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6019 - mean_absolute_error: 0.3023 - val_loss: 0.5827 - val_mean_absolute_error: 0.2954\n",
            "Epoch 72/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6017 - mean_absolute_error: 0.3019 - val_loss: 0.5826 - val_mean_absolute_error: 0.2940\n",
            "Epoch 73/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6016 - mean_absolute_error: 0.3016 - val_loss: 0.5827 - val_mean_absolute_error: 0.2942\n",
            "Epoch 74/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6005 - mean_absolute_error: 0.3021 - val_loss: 0.5829 - val_mean_absolute_error: 0.2909\n",
            "Epoch 75/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6019 - mean_absolute_error: 0.3012 - val_loss: 0.5826 - val_mean_absolute_error: 0.2921\n",
            "Epoch 76/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6023 - mean_absolute_error: 0.3017 - val_loss: 0.5825 - val_mean_absolute_error: 0.2954\n",
            "Epoch 77/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6021 - mean_absolute_error: 0.3014 - val_loss: 0.5824 - val_mean_absolute_error: 0.2942\n",
            "Epoch 78/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6008 - mean_absolute_error: 0.3016 - val_loss: 0.5825 - val_mean_absolute_error: 0.2948\n",
            "Epoch 79/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6005 - mean_absolute_error: 0.3016 - val_loss: 0.5823 - val_mean_absolute_error: 0.2926\n",
            "Epoch 80/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6013 - mean_absolute_error: 0.3013 - val_loss: 0.5823 - val_mean_absolute_error: 0.2942\n",
            "Epoch 81/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5999 - mean_absolute_error: 0.3012 - val_loss: 0.5822 - val_mean_absolute_error: 0.2934\n",
            "Epoch 82/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6004 - mean_absolute_error: 0.3010 - val_loss: 0.5821 - val_mean_absolute_error: 0.2934\n",
            "Epoch 83/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5992 - mean_absolute_error: 0.3008 - val_loss: 0.5822 - val_mean_absolute_error: 0.2940\n",
            "Epoch 84/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6009 - mean_absolute_error: 0.3011 - val_loss: 0.5823 - val_mean_absolute_error: 0.2953\n",
            "Epoch 85/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6007 - mean_absolute_error: 0.3007 - val_loss: 0.5821 - val_mean_absolute_error: 0.2927\n",
            "Epoch 86/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6004 - mean_absolute_error: 0.3010 - val_loss: 0.5821 - val_mean_absolute_error: 0.2928\n",
            "Epoch 87/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6005 - mean_absolute_error: 0.3007 - val_loss: 0.5820 - val_mean_absolute_error: 0.2927\n",
            "Epoch 88/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6008 - mean_absolute_error: 0.3006 - val_loss: 0.5820 - val_mean_absolute_error: 0.2938\n",
            "Epoch 89/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5998 - mean_absolute_error: 0.3006 - val_loss: 0.5820 - val_mean_absolute_error: 0.2926\n",
            "Epoch 90/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5993 - mean_absolute_error: 0.3003 - val_loss: 0.5821 - val_mean_absolute_error: 0.2943\n",
            "Epoch 91/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5993 - mean_absolute_error: 0.3007 - val_loss: 0.5818 - val_mean_absolute_error: 0.2927\n",
            "Epoch 92/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5998 - mean_absolute_error: 0.3002 - val_loss: 0.5822 - val_mean_absolute_error: 0.2905\n",
            "Epoch 93/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5988 - mean_absolute_error: 0.3004 - val_loss: 0.5821 - val_mean_absolute_error: 0.2921\n",
            "Epoch 94/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5989 - mean_absolute_error: 0.3005 - val_loss: 0.5818 - val_mean_absolute_error: 0.2937\n",
            "Epoch 95/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5994 - mean_absolute_error: 0.3001 - val_loss: 0.5819 - val_mean_absolute_error: 0.2926\n",
            "Epoch 96/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.6003 - mean_absolute_error: 0.2999 - val_loss: 0.5820 - val_mean_absolute_error: 0.2909\n",
            "Epoch 97/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5982 - mean_absolute_error: 0.3004 - val_loss: 0.5819 - val_mean_absolute_error: 0.2951\n",
            "Epoch 98/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5991 - mean_absolute_error: 0.2995 - val_loss: 0.5820 - val_mean_absolute_error: 0.2909\n",
            "Epoch 99/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5983 - mean_absolute_error: 0.3000 - val_loss: 0.5818 - val_mean_absolute_error: 0.2916\n",
            "Epoch 100/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5989 - mean_absolute_error: 0.2999 - val_loss: 0.5817 - val_mean_absolute_error: 0.2932\n",
            "Epoch 101/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5988 - mean_absolute_error: 0.3001 - val_loss: 0.5817 - val_mean_absolute_error: 0.2913\n",
            "Epoch 102/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5982 - mean_absolute_error: 0.2997 - val_loss: 0.5817 - val_mean_absolute_error: 0.2905\n",
            "Epoch 103/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5978 - mean_absolute_error: 0.2991 - val_loss: 0.5818 - val_mean_absolute_error: 0.2940\n",
            "Epoch 104/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5991 - mean_absolute_error: 0.2996 - val_loss: 0.5816 - val_mean_absolute_error: 0.2932\n",
            "Epoch 105/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5980 - mean_absolute_error: 0.2992 - val_loss: 0.5816 - val_mean_absolute_error: 0.2917\n",
            "Epoch 106/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5992 - mean_absolute_error: 0.2992 - val_loss: 0.5817 - val_mean_absolute_error: 0.2902\n",
            "Epoch 107/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5990 - mean_absolute_error: 0.2991 - val_loss: 0.5816 - val_mean_absolute_error: 0.2937\n",
            "Epoch 108/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5980 - mean_absolute_error: 0.2992 - val_loss: 0.5819 - val_mean_absolute_error: 0.2901\n",
            "Epoch 109/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5996 - mean_absolute_error: 0.2991 - val_loss: 0.5818 - val_mean_absolute_error: 0.2902\n",
            "Epoch 110/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5973 - mean_absolute_error: 0.2992 - val_loss: 0.5816 - val_mean_absolute_error: 0.2911\n",
            "Epoch 111/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5971 - mean_absolute_error: 0.2992 - val_loss: 0.5817 - val_mean_absolute_error: 0.2898\n",
            "Epoch 112/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5978 - mean_absolute_error: 0.2991 - val_loss: 0.5814 - val_mean_absolute_error: 0.2906\n",
            "Epoch 113/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5964 - mean_absolute_error: 0.2986 - val_loss: 0.5814 - val_mean_absolute_error: 0.2923\n",
            "Epoch 114/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5974 - mean_absolute_error: 0.2992 - val_loss: 0.5812 - val_mean_absolute_error: 0.2917\n",
            "Epoch 115/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5979 - mean_absolute_error: 0.2988 - val_loss: 0.5812 - val_mean_absolute_error: 0.2923\n",
            "Epoch 116/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5978 - mean_absolute_error: 0.2985 - val_loss: 0.5813 - val_mean_absolute_error: 0.2905\n",
            "Epoch 117/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5985 - mean_absolute_error: 0.2988 - val_loss: 0.5814 - val_mean_absolute_error: 0.2899\n",
            "Epoch 118/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5964 - mean_absolute_error: 0.2991 - val_loss: 0.5813 - val_mean_absolute_error: 0.2913\n",
            "Epoch 119/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5976 - mean_absolute_error: 0.2991 - val_loss: 0.5813 - val_mean_absolute_error: 0.2921\n",
            "Epoch 120/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5981 - mean_absolute_error: 0.2991 - val_loss: 0.5813 - val_mean_absolute_error: 0.2916\n",
            "Epoch 121/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5975 - mean_absolute_error: 0.2987 - val_loss: 0.5816 - val_mean_absolute_error: 0.2905\n",
            "Epoch 122/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5980 - mean_absolute_error: 0.2989 - val_loss: 0.5814 - val_mean_absolute_error: 0.2942\n",
            "Epoch 123/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5979 - mean_absolute_error: 0.2988 - val_loss: 0.5814 - val_mean_absolute_error: 0.2906\n",
            "Epoch 124/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5966 - mean_absolute_error: 0.2982 - val_loss: 0.5815 - val_mean_absolute_error: 0.2900\n",
            "Epoch 125/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5959 - mean_absolute_error: 0.2984 - val_loss: 0.5813 - val_mean_absolute_error: 0.2925\n",
            "Epoch 126/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5967 - mean_absolute_error: 0.2984 - val_loss: 0.5811 - val_mean_absolute_error: 0.2907\n",
            "Epoch 127/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5962 - mean_absolute_error: 0.2984 - val_loss: 0.5811 - val_mean_absolute_error: 0.2907\n",
            "Epoch 128/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5972 - mean_absolute_error: 0.2979 - val_loss: 0.5812 - val_mean_absolute_error: 0.2905\n",
            "Epoch 129/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5964 - mean_absolute_error: 0.2986 - val_loss: 0.5813 - val_mean_absolute_error: 0.2891\n",
            "Epoch 130/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5956 - mean_absolute_error: 0.2982 - val_loss: 0.5810 - val_mean_absolute_error: 0.2905\n",
            "Epoch 131/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5961 - mean_absolute_error: 0.2981 - val_loss: 0.5810 - val_mean_absolute_error: 0.2911\n",
            "Epoch 132/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5968 - mean_absolute_error: 0.2980 - val_loss: 0.5813 - val_mean_absolute_error: 0.2896\n",
            "Epoch 133/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5951 - mean_absolute_error: 0.2980 - val_loss: 0.5811 - val_mean_absolute_error: 0.2923\n",
            "Epoch 134/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5955 - mean_absolute_error: 0.2976 - val_loss: 0.5814 - val_mean_absolute_error: 0.2897\n",
            "Epoch 135/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5948 - mean_absolute_error: 0.2981 - val_loss: 0.5811 - val_mean_absolute_error: 0.2923\n",
            "Epoch 136/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5954 - mean_absolute_error: 0.2983 - val_loss: 0.5812 - val_mean_absolute_error: 0.2935\n",
            "Epoch 137/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5962 - mean_absolute_error: 0.2982 - val_loss: 0.5811 - val_mean_absolute_error: 0.2933\n",
            "Epoch 138/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5940 - mean_absolute_error: 0.2978 - val_loss: 0.5814 - val_mean_absolute_error: 0.2900\n",
            "Epoch 139/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5959 - mean_absolute_error: 0.2978 - val_loss: 0.5811 - val_mean_absolute_error: 0.2926\n",
            "Epoch 140/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5939 - mean_absolute_error: 0.2980 - val_loss: 0.5810 - val_mean_absolute_error: 0.2917\n",
            "Epoch 141/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5950 - mean_absolute_error: 0.2979 - val_loss: 0.5809 - val_mean_absolute_error: 0.2921\n",
            "Epoch 142/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5951 - mean_absolute_error: 0.2973 - val_loss: 0.5811 - val_mean_absolute_error: 0.2905\n",
            "Epoch 143/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5950 - mean_absolute_error: 0.2977 - val_loss: 0.5809 - val_mean_absolute_error: 0.2917\n",
            "Epoch 144/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5959 - mean_absolute_error: 0.2977 - val_loss: 0.5811 - val_mean_absolute_error: 0.2900\n",
            "Epoch 145/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5960 - mean_absolute_error: 0.2981 - val_loss: 0.5808 - val_mean_absolute_error: 0.2918\n",
            "Epoch 146/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5946 - mean_absolute_error: 0.2974 - val_loss: 0.5810 - val_mean_absolute_error: 0.2933\n",
            "Epoch 147/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5950 - mean_absolute_error: 0.2976 - val_loss: 0.5810 - val_mean_absolute_error: 0.2912\n",
            "Epoch 148/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5944 - mean_absolute_error: 0.2976 - val_loss: 0.5809 - val_mean_absolute_error: 0.2903\n",
            "Epoch 149/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5930 - mean_absolute_error: 0.2971 - val_loss: 0.5810 - val_mean_absolute_error: 0.2903\n",
            "Epoch 150/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5949 - mean_absolute_error: 0.2974 - val_loss: 0.5809 - val_mean_absolute_error: 0.2904\n",
            "Epoch 151/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5949 - mean_absolute_error: 0.2971 - val_loss: 0.5812 - val_mean_absolute_error: 0.2892\n",
            "Epoch 152/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5940 - mean_absolute_error: 0.2974 - val_loss: 0.5811 - val_mean_absolute_error: 0.2895\n",
            "Epoch 153/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5943 - mean_absolute_error: 0.2973 - val_loss: 0.5810 - val_mean_absolute_error: 0.2897\n",
            "Epoch 154/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5947 - mean_absolute_error: 0.2973 - val_loss: 0.5810 - val_mean_absolute_error: 0.2925\n",
            "Epoch 155/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5944 - mean_absolute_error: 0.2971 - val_loss: 0.5809 - val_mean_absolute_error: 0.2917\n",
            "Epoch 156/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5937 - mean_absolute_error: 0.2970 - val_loss: 0.5809 - val_mean_absolute_error: 0.2915\n",
            "Epoch 157/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5935 - mean_absolute_error: 0.2972 - val_loss: 0.5810 - val_mean_absolute_error: 0.2899\n",
            "Epoch 158/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5942 - mean_absolute_error: 0.2975 - val_loss: 0.5814 - val_mean_absolute_error: 0.2892\n",
            "Epoch 159/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5920 - mean_absolute_error: 0.2971 - val_loss: 0.5811 - val_mean_absolute_error: 0.2889\n",
            "Epoch 160/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5942 - mean_absolute_error: 0.2971 - val_loss: 0.5809 - val_mean_absolute_error: 0.2908\n",
            "Epoch 161/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5938 - mean_absolute_error: 0.2970 - val_loss: 0.5811 - val_mean_absolute_error: 0.2889\n",
            "Epoch 162/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5926 - mean_absolute_error: 0.2966 - val_loss: 0.5809 - val_mean_absolute_error: 0.2933\n",
            "Epoch 163/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5925 - mean_absolute_error: 0.2974 - val_loss: 0.5808 - val_mean_absolute_error: 0.2921\n",
            "Epoch 164/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5929 - mean_absolute_error: 0.2966 - val_loss: 0.5811 - val_mean_absolute_error: 0.2903\n",
            "Epoch 165/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5931 - mean_absolute_error: 0.2970 - val_loss: 0.5810 - val_mean_absolute_error: 0.2901\n",
            "Epoch 166/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5928 - mean_absolute_error: 0.2969 - val_loss: 0.5810 - val_mean_absolute_error: 0.2933\n",
            "Epoch 167/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5925 - mean_absolute_error: 0.2972 - val_loss: 0.5810 - val_mean_absolute_error: 0.2899\n",
            "Epoch 168/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5922 - mean_absolute_error: 0.2962 - val_loss: 0.5813 - val_mean_absolute_error: 0.2900\n",
            "Epoch 169/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5928 - mean_absolute_error: 0.2969 - val_loss: 0.5808 - val_mean_absolute_error: 0.2894\n",
            "Epoch 170/500\n",
            "234/234 [==============================] - 1s 3ms/step - loss: 0.5929 - mean_absolute_error: 0.2964 - val_loss: 0.5810 - val_mean_absolute_error: 0.2892\n"
          ]
        }
      ],
      "source": [
        "print('\\nFitting DNN (Retrieval Module - Snow):\\n')\n",
        "batch_size2 = 600\n",
        "history_retrieval_snow = model_retrieval_snow.fit(Xf_snow_trn_retrieval, yf_snow_trn_retrieval, epochs=500,\n",
        "                                validation_split=.2, batch_size = batch_size2,\n",
        "                                callbacks=callbacks_list, verbose=1)"
      ],
      "id": "shnu2-AiPtfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vwF7sMsNPtfv",
        "outputId": "b14ea61e-ea80-4c94-aecd-cf49e87bc55f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1681aaab6a0>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_retrieval_snow.history[\"val_mean_absolute_error\"]\n",
        "loss = history_retrieval_snow.history[\"mean_absolute_error\"]\n",
        "\n",
        "epochs = range(1, 171)\n",
        "plt.plot(epochs, val_loss[:], \"r-\",\n",
        "label=\"Validation Loss\")\n",
        "plt.plot(epochs, loss[:], \"b-\",\n",
        "label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "id": "vwF7sMsNPtfv"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fzyOMbYnPtfw"
      },
      "outputs": [],
      "source": [
        "predictions_snow = model_retrieval_snow.predict(Xf_snow_tst_retrieval)"
      ],
      "id": "fzyOMbYnPtfw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vBXxyPrEPtfw",
        "outputId": "a87581f9-90e3-412d-9789-3e2d72c27233"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "126/126 [==============================] - 0s 665us/step - loss: 0.5972 - mean_absolute_error: 0.3043\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.5972467660903931, 0.3043079078197479]"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_retrieval_snow.evaluate(Xf_snow_tst_retrieval, yf_snow_tst_retrieval, batch_size = batch_size2)"
      ],
      "id": "vBXxyPrEPtfw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BsNOBiQlPtfw"
      },
      "source": [
        "# Checking Outputs"
      ],
      "id": "BsNOBiQlPtfw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cHvoq17fPtfx"
      },
      "source": [
        "### **2.2.1 Rainfall retrieval**"
      ],
      "id": "cHvoq17fPtfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "07QX_Sh7Ptfx"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "hidden_units = 90\n",
        "dropout = 0\n",
        "\n",
        "# COAST\n",
        "model_retrieval_rain = Sequential()\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(hidden_units))\n",
        "model_retrieval_rain.add(Activation('relu'))\n",
        "model_retrieval_rain.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval_rain.add(Dense(1))\n",
        "model_retrieval_rain.add(Activation('relu'))"
      ],
      "id": "07QX_Sh7Ptfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c56uZMtPPtfx"
      },
      "outputs": [],
      "source": [
        "model_retrieval_rain.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss = root_mean_squared_error,\n",
        "              metrics= mean_absolute_error)"
      ],
      "id": "c56uZMtPPtfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5XbySXxuPtfx"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=25,),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint_path.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    )    \n",
        "]"
      ],
      "id": "5XbySXxuPtfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtYqGaYIPtfx",
        "outputId": "d6ff4d06-2c37-4ca1-bd32-7521da75df71"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting DNN (Retrieval Module - Rain):\n",
            "\n",
            "Epoch 1/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 5.6829 - mean_absolute_error: 2.2335 - val_loss: 5.5839 - val_mean_absolute_error: 2.0815\n",
            "Epoch 2/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 5.3156 - mean_absolute_error: 1.9165 - val_loss: 5.1809 - val_mean_absolute_error: 1.8070\n",
            "Epoch 3/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.9547 - mean_absolute_error: 1.7432 - val_loss: 4.8670 - val_mean_absolute_error: 1.7385\n",
            "Epoch 4/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.7636 - mean_absolute_error: 1.7613 - val_loss: 4.7804 - val_mean_absolute_error: 1.7864\n",
            "Epoch 5/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.7103 - mean_absolute_error: 1.7963 - val_loss: 4.7380 - val_mean_absolute_error: 1.7966\n",
            "Epoch 6/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.6684 - mean_absolute_error: 1.8008 - val_loss: 4.7003 - val_mean_absolute_error: 1.7848\n",
            "Epoch 7/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.6374 - mean_absolute_error: 1.7872 - val_loss: 4.6615 - val_mean_absolute_error: 1.7934\n",
            "Epoch 8/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.5936 - mean_absolute_error: 1.7831 - val_loss: 4.6217 - val_mean_absolute_error: 1.7842\n",
            "Epoch 9/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.5522 - mean_absolute_error: 1.7706 - val_loss: 4.5800 - val_mean_absolute_error: 1.7708\n",
            "Epoch 10/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.5105 - mean_absolute_error: 1.7573 - val_loss: 4.5381 - val_mean_absolute_error: 1.7580\n",
            "Epoch 11/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.4713 - mean_absolute_error: 1.7427 - val_loss: 4.4938 - val_mean_absolute_error: 1.7242\n",
            "Epoch 12/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.4225 - mean_absolute_error: 1.7199 - val_loss: 4.4477 - val_mean_absolute_error: 1.6945\n",
            "Epoch 13/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.3844 - mean_absolute_error: 1.6936 - val_loss: 4.4027 - val_mean_absolute_error: 1.6703\n",
            "Epoch 14/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.3453 - mean_absolute_error: 1.6710 - val_loss: 4.3557 - val_mean_absolute_error: 1.6452\n",
            "Epoch 15/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.2906 - mean_absolute_error: 1.6410 - val_loss: 4.3082 - val_mean_absolute_error: 1.6300\n",
            "Epoch 16/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.2540 - mean_absolute_error: 1.6223 - val_loss: 4.2645 - val_mean_absolute_error: 1.5871\n",
            "Epoch 17/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.2108 - mean_absolute_error: 1.5903 - val_loss: 4.2247 - val_mean_absolute_error: 1.5698\n",
            "Epoch 18/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.1826 - mean_absolute_error: 1.5672 - val_loss: 4.1895 - val_mean_absolute_error: 1.5607\n",
            "Epoch 19/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.1397 - mean_absolute_error: 1.5488 - val_loss: 4.1580 - val_mean_absolute_error: 1.5282\n",
            "Epoch 20/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.1182 - mean_absolute_error: 1.5279 - val_loss: 4.1325 - val_mean_absolute_error: 1.5235\n",
            "Epoch 21/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0833 - mean_absolute_error: 1.5140 - val_loss: 4.1113 - val_mean_absolute_error: 1.4755\n",
            "Epoch 22/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0674 - mean_absolute_error: 1.4964 - val_loss: 4.0924 - val_mean_absolute_error: 1.4729\n",
            "Epoch 23/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0541 - mean_absolute_error: 1.4853 - val_loss: 4.0770 - val_mean_absolute_error: 1.4725\n",
            "Epoch 24/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0354 - mean_absolute_error: 1.4773 - val_loss: 4.0647 - val_mean_absolute_error: 1.4477\n",
            "Epoch 25/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0220 - mean_absolute_error: 1.4672 - val_loss: 4.0547 - val_mean_absolute_error: 1.4581\n",
            "Epoch 26/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0021 - mean_absolute_error: 1.4542 - val_loss: 4.0455 - val_mean_absolute_error: 1.4383\n",
            "Epoch 27/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 4.0246 - mean_absolute_error: 1.4467 - val_loss: 4.0377 - val_mean_absolute_error: 1.4313\n",
            "Epoch 28/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9941 - mean_absolute_error: 1.4382 - val_loss: 4.0316 - val_mean_absolute_error: 1.4365\n",
            "Epoch 29/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 4.0123 - mean_absolute_error: 1.4343 - val_loss: 4.0258 - val_mean_absolute_error: 1.4145\n",
            "Epoch 30/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9966 - mean_absolute_error: 1.4292 - val_loss: 4.0196 - val_mean_absolute_error: 1.4167\n",
            "Epoch 31/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9996 - mean_absolute_error: 1.4250 - val_loss: 4.0145 - val_mean_absolute_error: 1.4011\n",
            "Epoch 32/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9949 - mean_absolute_error: 1.4178 - val_loss: 4.0098 - val_mean_absolute_error: 1.3920\n",
            "Epoch 33/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9698 - mean_absolute_error: 1.4092 - val_loss: 4.0050 - val_mean_absolute_error: 1.3954\n",
            "Epoch 34/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9915 - mean_absolute_error: 1.4109 - val_loss: 4.0004 - val_mean_absolute_error: 1.3894\n",
            "Epoch 35/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9545 - mean_absolute_error: 1.3993 - val_loss: 3.9966 - val_mean_absolute_error: 1.3833\n",
            "Epoch 36/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.9710 - mean_absolute_error: 1.3968 - val_loss: 3.9936 - val_mean_absolute_error: 1.3735\n",
            "Epoch 37/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9525 - mean_absolute_error: 1.3926 - val_loss: 3.9905 - val_mean_absolute_error: 1.3690\n",
            "Epoch 38/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9601 - mean_absolute_error: 1.3912 - val_loss: 3.9883 - val_mean_absolute_error: 1.3576\n",
            "Epoch 39/500\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 3.9649 - mean_absolute_error: 1.3822 - val_loss: 3.9845 - val_mean_absolute_error: 1.4053\n",
            "Epoch 40/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9566 - mean_absolute_error: 1.3872 - val_loss: 3.9789 - val_mean_absolute_error: 1.3739\n",
            "Epoch 41/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9431 - mean_absolute_error: 1.3823 - val_loss: 3.9773 - val_mean_absolute_error: 1.3544\n",
            "Epoch 42/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9310 - mean_absolute_error: 1.3738 - val_loss: 3.9734 - val_mean_absolute_error: 1.3688\n",
            "Epoch 43/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9309 - mean_absolute_error: 1.3757 - val_loss: 3.9710 - val_mean_absolute_error: 1.3581\n",
            "Epoch 44/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9333 - mean_absolute_error: 1.3713 - val_loss: 3.9677 - val_mean_absolute_error: 1.3620\n",
            "Epoch 45/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9269 - mean_absolute_error: 1.3688 - val_loss: 3.9675 - val_mean_absolute_error: 1.3354\n",
            "Epoch 46/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9509 - mean_absolute_error: 1.3636 - val_loss: 3.9632 - val_mean_absolute_error: 1.3423\n",
            "Epoch 47/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9381 - mean_absolute_error: 1.3636 - val_loss: 3.9601 - val_mean_absolute_error: 1.3476\n",
            "Epoch 48/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9115 - mean_absolute_error: 1.3563 - val_loss: 3.9571 - val_mean_absolute_error: 1.3500\n",
            "Epoch 49/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9223 - mean_absolute_error: 1.3571 - val_loss: 3.9545 - val_mean_absolute_error: 1.3476\n",
            "Epoch 50/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9183 - mean_absolute_error: 1.3571 - val_loss: 3.9520 - val_mean_absolute_error: 1.3467\n",
            "Epoch 51/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9024 - mean_absolute_error: 1.3536 - val_loss: 3.9512 - val_mean_absolute_error: 1.3292\n",
            "Epoch 52/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9203 - mean_absolute_error: 1.3542 - val_loss: 3.9469 - val_mean_absolute_error: 1.3468\n",
            "Epoch 53/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9333 - mean_absolute_error: 1.3534 - val_loss: 3.9441 - val_mean_absolute_error: 1.3379\n",
            "Epoch 54/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9225 - mean_absolute_error: 1.3491 - val_loss: 3.9415 - val_mean_absolute_error: 1.3399\n",
            "Epoch 55/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9212 - mean_absolute_error: 1.3478 - val_loss: 3.9393 - val_mean_absolute_error: 1.3359\n",
            "Epoch 56/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9017 - mean_absolute_error: 1.3425 - val_loss: 3.9381 - val_mean_absolute_error: 1.3255\n",
            "Epoch 57/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9050 - mean_absolute_error: 1.3396 - val_loss: 3.9358 - val_mean_absolute_error: 1.3428\n",
            "Epoch 58/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9070 - mean_absolute_error: 1.3437 - val_loss: 3.9338 - val_mean_absolute_error: 1.3355\n",
            "Epoch 59/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8826 - mean_absolute_error: 1.3410 - val_loss: 3.9338 - val_mean_absolute_error: 1.3141\n",
            "Epoch 60/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8981 - mean_absolute_error: 1.3345 - val_loss: 3.9299 - val_mean_absolute_error: 1.3354\n",
            "Epoch 61/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8818 - mean_absolute_error: 1.3355 - val_loss: 3.9283 - val_mean_absolute_error: 1.3222\n",
            "Epoch 62/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.9040 - mean_absolute_error: 1.3333 - val_loss: 3.9269 - val_mean_absolute_error: 1.3158\n",
            "Epoch 63/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8878 - mean_absolute_error: 1.3297 - val_loss: 3.9242 - val_mean_absolute_error: 1.3213\n",
            "Epoch 64/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8822 - mean_absolute_error: 1.3347 - val_loss: 3.9228 - val_mean_absolute_error: 1.3152\n",
            "Epoch 65/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8877 - mean_absolute_error: 1.3345 - val_loss: 3.9220 - val_mean_absolute_error: 1.3043\n",
            "Epoch 66/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8851 - mean_absolute_error: 1.3254 - val_loss: 3.9190 - val_mean_absolute_error: 1.3148\n",
            "Epoch 67/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8604 - mean_absolute_error: 1.3250 - val_loss: 3.9168 - val_mean_absolute_error: 1.3223\n",
            "Epoch 68/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8583 - mean_absolute_error: 1.3253 - val_loss: 3.9153 - val_mean_absolute_error: 1.3225\n",
            "Epoch 69/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8891 - mean_absolute_error: 1.3267 - val_loss: 3.9141 - val_mean_absolute_error: 1.3026\n",
            "Epoch 70/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8779 - mean_absolute_error: 1.3185 - val_loss: 3.9122 - val_mean_absolute_error: 1.3046\n",
            "Epoch 71/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.8706 - mean_absolute_error: 1.3183 - val_loss: 3.9123 - val_mean_absolute_error: 1.2992\n",
            "Epoch 72/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8584 - mean_absolute_error: 1.3242 - val_loss: 3.9086 - val_mean_absolute_error: 1.3044\n",
            "Epoch 73/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8708 - mean_absolute_error: 1.3203 - val_loss: 3.9070 - val_mean_absolute_error: 1.2973\n",
            "Epoch 74/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8531 - mean_absolute_error: 1.3172 - val_loss: 3.9042 - val_mean_absolute_error: 1.3058\n",
            "Epoch 75/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8572 - mean_absolute_error: 1.3171 - val_loss: 3.9021 - val_mean_absolute_error: 1.3077\n",
            "Epoch 76/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8631 - mean_absolute_error: 1.3171 - val_loss: 3.9015 - val_mean_absolute_error: 1.2965\n",
            "Epoch 77/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8639 - mean_absolute_error: 1.3136 - val_loss: 3.8991 - val_mean_absolute_error: 1.3106\n",
            "Epoch 78/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8560 - mean_absolute_error: 1.3127 - val_loss: 3.8973 - val_mean_absolute_error: 1.3091\n",
            "Epoch 79/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8448 - mean_absolute_error: 1.3151 - val_loss: 3.8953 - val_mean_absolute_error: 1.3042\n",
            "Epoch 80/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8358 - mean_absolute_error: 1.3090 - val_loss: 3.8933 - val_mean_absolute_error: 1.3005\n",
            "Epoch 81/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8469 - mean_absolute_error: 1.3081 - val_loss: 3.8923 - val_mean_absolute_error: 1.2945\n",
            "Epoch 82/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8395 - mean_absolute_error: 1.3074 - val_loss: 3.8912 - val_mean_absolute_error: 1.3201\n",
            "Epoch 83/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8468 - mean_absolute_error: 1.3093 - val_loss: 3.8904 - val_mean_absolute_error: 1.2818\n",
            "Epoch 84/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8389 - mean_absolute_error: 1.3052 - val_loss: 3.8864 - val_mean_absolute_error: 1.2852\n",
            "Epoch 85/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8481 - mean_absolute_error: 1.3028 - val_loss: 3.8854 - val_mean_absolute_error: 1.2873\n",
            "Epoch 86/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8339 - mean_absolute_error: 1.3047 - val_loss: 3.8822 - val_mean_absolute_error: 1.3020\n",
            "Epoch 87/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8348 - mean_absolute_error: 1.3036 - val_loss: 3.8819 - val_mean_absolute_error: 1.2818\n",
            "Epoch 88/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8353 - mean_absolute_error: 1.3006 - val_loss: 3.8786 - val_mean_absolute_error: 1.2986\n",
            "Epoch 89/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8315 - mean_absolute_error: 1.3025 - val_loss: 3.8774 - val_mean_absolute_error: 1.2913\n",
            "Epoch 90/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8307 - mean_absolute_error: 1.3003 - val_loss: 3.8756 - val_mean_absolute_error: 1.2903\n",
            "Epoch 91/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8318 - mean_absolute_error: 1.3012 - val_loss: 3.8739 - val_mean_absolute_error: 1.2902\n",
            "Epoch 92/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8183 - mean_absolute_error: 1.2986 - val_loss: 3.8723 - val_mean_absolute_error: 1.3092\n",
            "Epoch 93/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8268 - mean_absolute_error: 1.3031 - val_loss: 3.8700 - val_mean_absolute_error: 1.2938\n",
            "Epoch 94/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8148 - mean_absolute_error: 1.2943 - val_loss: 3.8686 - val_mean_absolute_error: 1.2975\n",
            "Epoch 95/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8029 - mean_absolute_error: 1.2943 - val_loss: 3.8669 - val_mean_absolute_error: 1.2845\n",
            "Epoch 96/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8135 - mean_absolute_error: 1.2931 - val_loss: 3.8650 - val_mean_absolute_error: 1.2901\n",
            "Epoch 97/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8102 - mean_absolute_error: 1.2975 - val_loss: 3.8631 - val_mean_absolute_error: 1.2901\n",
            "Epoch 98/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8160 - mean_absolute_error: 1.2943 - val_loss: 3.8614 - val_mean_absolute_error: 1.2968\n",
            "Epoch 99/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8016 - mean_absolute_error: 1.2902 - val_loss: 3.8592 - val_mean_absolute_error: 1.2957\n",
            "Epoch 100/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8018 - mean_absolute_error: 1.2924 - val_loss: 3.8581 - val_mean_absolute_error: 1.3009\n",
            "Epoch 101/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.7999 - mean_absolute_error: 1.2915 - val_loss: 3.8613 - val_mean_absolute_error: 1.2630\n",
            "Epoch 102/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7923 - mean_absolute_error: 1.2900 - val_loss: 3.8543 - val_mean_absolute_error: 1.2934\n",
            "Epoch 103/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7894 - mean_absolute_error: 1.2894 - val_loss: 3.8524 - val_mean_absolute_error: 1.2919\n",
            "Epoch 104/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7758 - mean_absolute_error: 1.2898 - val_loss: 3.8509 - val_mean_absolute_error: 1.2881\n",
            "Epoch 105/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7927 - mean_absolute_error: 1.2918 - val_loss: 3.8492 - val_mean_absolute_error: 1.2785\n",
            "Epoch 106/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7819 - mean_absolute_error: 1.2882 - val_loss: 3.8489 - val_mean_absolute_error: 1.3058\n",
            "Epoch 107/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7840 - mean_absolute_error: 1.2882 - val_loss: 3.8470 - val_mean_absolute_error: 1.2751\n",
            "Epoch 108/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.8034 - mean_absolute_error: 1.2861 - val_loss: 3.8491 - val_mean_absolute_error: 1.3282\n",
            "Epoch 109/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7767 - mean_absolute_error: 1.2892 - val_loss: 3.8424 - val_mean_absolute_error: 1.2849\n",
            "Epoch 110/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7878 - mean_absolute_error: 1.2867 - val_loss: 3.8420 - val_mean_absolute_error: 1.2765\n",
            "Epoch 111/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7952 - mean_absolute_error: 1.2877 - val_loss: 3.8398 - val_mean_absolute_error: 1.2951\n",
            "Epoch 112/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7819 - mean_absolute_error: 1.2864 - val_loss: 3.8382 - val_mean_absolute_error: 1.2749\n",
            "Epoch 113/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7807 - mean_absolute_error: 1.2867 - val_loss: 3.8372 - val_mean_absolute_error: 1.2729\n",
            "Epoch 114/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7716 - mean_absolute_error: 1.2834 - val_loss: 3.8350 - val_mean_absolute_error: 1.2783\n",
            "Epoch 115/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7679 - mean_absolute_error: 1.2861 - val_loss: 3.8334 - val_mean_absolute_error: 1.2766\n",
            "Epoch 116/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7576 - mean_absolute_error: 1.2790 - val_loss: 3.8321 - val_mean_absolute_error: 1.2839\n",
            "Epoch 117/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7666 - mean_absolute_error: 1.2811 - val_loss: 3.8307 - val_mean_absolute_error: 1.2762\n",
            "Epoch 118/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7724 - mean_absolute_error: 1.2790 - val_loss: 3.8301 - val_mean_absolute_error: 1.2754\n",
            "Epoch 119/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7546 - mean_absolute_error: 1.2838 - val_loss: 3.8280 - val_mean_absolute_error: 1.2918\n",
            "Epoch 120/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7671 - mean_absolute_error: 1.2828 - val_loss: 3.8258 - val_mean_absolute_error: 1.2781\n",
            "Epoch 121/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7563 - mean_absolute_error: 1.2783 - val_loss: 3.8240 - val_mean_absolute_error: 1.2876\n",
            "Epoch 122/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7632 - mean_absolute_error: 1.2787 - val_loss: 3.8223 - val_mean_absolute_error: 1.2804\n",
            "Epoch 123/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7466 - mean_absolute_error: 1.2823 - val_loss: 3.8217 - val_mean_absolute_error: 1.2690\n",
            "Epoch 124/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7605 - mean_absolute_error: 1.2763 - val_loss: 3.8198 - val_mean_absolute_error: 1.2820\n",
            "Epoch 125/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7503 - mean_absolute_error: 1.2772 - val_loss: 3.8183 - val_mean_absolute_error: 1.2834\n",
            "Epoch 126/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7436 - mean_absolute_error: 1.2819 - val_loss: 3.8212 - val_mean_absolute_error: 1.2517\n",
            "Epoch 127/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7304 - mean_absolute_error: 1.2743 - val_loss: 3.8146 - val_mean_absolute_error: 1.2838\n",
            "Epoch 128/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7601 - mean_absolute_error: 1.2801 - val_loss: 3.8139 - val_mean_absolute_error: 1.2649\n",
            "Epoch 129/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7478 - mean_absolute_error: 1.2738 - val_loss: 3.8121 - val_mean_absolute_error: 1.2790\n",
            "Epoch 130/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7410 - mean_absolute_error: 1.2762 - val_loss: 3.8104 - val_mean_absolute_error: 1.2731\n",
            "Epoch 131/500\n",
            "234/234 [==============================] - 1s 6ms/step - loss: 3.7576 - mean_absolute_error: 1.2757 - val_loss: 3.8092 - val_mean_absolute_error: 1.2625\n",
            "Epoch 132/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7321 - mean_absolute_error: 1.2733 - val_loss: 3.8085 - val_mean_absolute_error: 1.2615\n",
            "Epoch 133/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7479 - mean_absolute_error: 1.2765 - val_loss: 3.8055 - val_mean_absolute_error: 1.2670\n",
            "Epoch 134/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7301 - mean_absolute_error: 1.2701 - val_loss: 3.8052 - val_mean_absolute_error: 1.2702\n",
            "Epoch 135/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7313 - mean_absolute_error: 1.2737 - val_loss: 3.8030 - val_mean_absolute_error: 1.2838\n",
            "Epoch 136/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7300 - mean_absolute_error: 1.2768 - val_loss: 3.8012 - val_mean_absolute_error: 1.2684\n",
            "Epoch 137/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7270 - mean_absolute_error: 1.2727 - val_loss: 3.7998 - val_mean_absolute_error: 1.2626\n",
            "Epoch 138/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7269 - mean_absolute_error: 1.2716 - val_loss: 3.7986 - val_mean_absolute_error: 1.2589\n",
            "Epoch 139/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7257 - mean_absolute_error: 1.2694 - val_loss: 3.7961 - val_mean_absolute_error: 1.2723\n",
            "Epoch 140/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7444 - mean_absolute_error: 1.2718 - val_loss: 3.7951 - val_mean_absolute_error: 1.2786\n",
            "Epoch 141/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7151 - mean_absolute_error: 1.2714 - val_loss: 3.7935 - val_mean_absolute_error: 1.2710\n",
            "Epoch 142/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7105 - mean_absolute_error: 1.2687 - val_loss: 3.7931 - val_mean_absolute_error: 1.2605\n",
            "Epoch 143/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7113 - mean_absolute_error: 1.2678 - val_loss: 3.7914 - val_mean_absolute_error: 1.2608\n",
            "Epoch 144/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7110 - mean_absolute_error: 1.2656 - val_loss: 3.7897 - val_mean_absolute_error: 1.2707\n",
            "Epoch 145/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7158 - mean_absolute_error: 1.2688 - val_loss: 3.7896 - val_mean_absolute_error: 1.2588\n",
            "Epoch 146/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7124 - mean_absolute_error: 1.2685 - val_loss: 3.7872 - val_mean_absolute_error: 1.2798\n",
            "Epoch 147/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7114 - mean_absolute_error: 1.2700 - val_loss: 3.7854 - val_mean_absolute_error: 1.2686\n",
            "Epoch 148/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7204 - mean_absolute_error: 1.2657 - val_loss: 3.7856 - val_mean_absolute_error: 1.2911\n",
            "Epoch 149/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7027 - mean_absolute_error: 1.2698 - val_loss: 3.7825 - val_mean_absolute_error: 1.2743\n",
            "Epoch 150/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7125 - mean_absolute_error: 1.2674 - val_loss: 3.7811 - val_mean_absolute_error: 1.2634\n",
            "Epoch 151/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6971 - mean_absolute_error: 1.2667 - val_loss: 3.7809 - val_mean_absolute_error: 1.2732\n",
            "Epoch 152/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7136 - mean_absolute_error: 1.2639 - val_loss: 3.7800 - val_mean_absolute_error: 1.2634\n",
            "Epoch 153/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6902 - mean_absolute_error: 1.2640 - val_loss: 3.7793 - val_mean_absolute_error: 1.2735\n",
            "Epoch 154/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6952 - mean_absolute_error: 1.2647 - val_loss: 3.7784 - val_mean_absolute_error: 1.2813\n",
            "Epoch 155/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6975 - mean_absolute_error: 1.2666 - val_loss: 3.7777 - val_mean_absolute_error: 1.2839\n",
            "Epoch 156/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.7012 - mean_absolute_error: 1.2677 - val_loss: 3.7762 - val_mean_absolute_error: 1.2538\n",
            "Epoch 157/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6980 - mean_absolute_error: 1.2645 - val_loss: 3.7757 - val_mean_absolute_error: 1.2531\n",
            "Epoch 158/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6872 - mean_absolute_error: 1.2638 - val_loss: 3.7734 - val_mean_absolute_error: 1.2770\n",
            "Epoch 159/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6909 - mean_absolute_error: 1.2652 - val_loss: 3.7722 - val_mean_absolute_error: 1.2787\n",
            "Epoch 160/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6828 - mean_absolute_error: 1.2621 - val_loss: 3.7696 - val_mean_absolute_error: 1.2729\n",
            "Epoch 161/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6937 - mean_absolute_error: 1.2624 - val_loss: 3.7679 - val_mean_absolute_error: 1.2626\n",
            "Epoch 162/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6932 - mean_absolute_error: 1.2645 - val_loss: 3.7674 - val_mean_absolute_error: 1.2586\n",
            "Epoch 163/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6913 - mean_absolute_error: 1.2600 - val_loss: 3.7662 - val_mean_absolute_error: 1.2662\n",
            "Epoch 164/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6837 - mean_absolute_error: 1.2638 - val_loss: 3.7663 - val_mean_absolute_error: 1.2551\n",
            "Epoch 165/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6897 - mean_absolute_error: 1.2633 - val_loss: 3.7649 - val_mean_absolute_error: 1.2849\n",
            "Epoch 166/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6854 - mean_absolute_error: 1.2649 - val_loss: 3.7629 - val_mean_absolute_error: 1.2644\n",
            "Epoch 167/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6779 - mean_absolute_error: 1.2609 - val_loss: 3.7642 - val_mean_absolute_error: 1.2819\n",
            "Epoch 168/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6735 - mean_absolute_error: 1.2614 - val_loss: 3.7623 - val_mean_absolute_error: 1.2602\n",
            "Epoch 169/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6755 - mean_absolute_error: 1.2619 - val_loss: 3.7610 - val_mean_absolute_error: 1.2717\n",
            "Epoch 170/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6776 - mean_absolute_error: 1.2598 - val_loss: 3.7620 - val_mean_absolute_error: 1.2471\n",
            "Epoch 171/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6807 - mean_absolute_error: 1.2588 - val_loss: 3.7622 - val_mean_absolute_error: 1.2472\n",
            "Epoch 172/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6712 - mean_absolute_error: 1.2602 - val_loss: 3.7603 - val_mean_absolute_error: 1.2517\n",
            "Epoch 173/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6547 - mean_absolute_error: 1.2560 - val_loss: 3.7580 - val_mean_absolute_error: 1.2677\n",
            "Epoch 174/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6712 - mean_absolute_error: 1.2622 - val_loss: 3.7590 - val_mean_absolute_error: 1.2515\n",
            "Epoch 175/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6481 - mean_absolute_error: 1.2571 - val_loss: 3.7574 - val_mean_absolute_error: 1.2652\n",
            "Epoch 176/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6756 - mean_absolute_error: 1.2637 - val_loss: 3.7551 - val_mean_absolute_error: 1.2754\n",
            "Epoch 177/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6702 - mean_absolute_error: 1.2611 - val_loss: 3.7545 - val_mean_absolute_error: 1.2719\n",
            "Epoch 178/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6753 - mean_absolute_error: 1.2589 - val_loss: 3.7532 - val_mean_absolute_error: 1.2703\n",
            "Epoch 179/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6642 - mean_absolute_error: 1.2569 - val_loss: 3.7521 - val_mean_absolute_error: 1.2566\n",
            "Epoch 180/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6537 - mean_absolute_error: 1.2600 - val_loss: 3.7519 - val_mean_absolute_error: 1.2789\n",
            "Epoch 181/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6515 - mean_absolute_error: 1.2584 - val_loss: 3.7517 - val_mean_absolute_error: 1.2789\n",
            "Epoch 182/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6674 - mean_absolute_error: 1.2581 - val_loss: 3.7502 - val_mean_absolute_error: 1.2734\n",
            "Epoch 183/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6560 - mean_absolute_error: 1.2592 - val_loss: 3.7492 - val_mean_absolute_error: 1.2653\n",
            "Epoch 184/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6569 - mean_absolute_error: 1.2578 - val_loss: 3.7482 - val_mean_absolute_error: 1.2613\n",
            "Epoch 185/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6530 - mean_absolute_error: 1.2567 - val_loss: 3.7478 - val_mean_absolute_error: 1.2637\n",
            "Epoch 186/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6308 - mean_absolute_error: 1.2534 - val_loss: 3.7502 - val_mean_absolute_error: 1.2464\n",
            "Epoch 187/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6413 - mean_absolute_error: 1.2583 - val_loss: 3.7489 - val_mean_absolute_error: 1.2494\n",
            "Epoch 188/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6392 - mean_absolute_error: 1.2545 - val_loss: 3.7461 - val_mean_absolute_error: 1.2614\n",
            "Epoch 189/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6417 - mean_absolute_error: 1.2552 - val_loss: 3.7455 - val_mean_absolute_error: 1.2545\n",
            "Epoch 190/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6416 - mean_absolute_error: 1.2538 - val_loss: 3.7446 - val_mean_absolute_error: 1.2655\n",
            "Epoch 191/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6425 - mean_absolute_error: 1.2561 - val_loss: 3.7439 - val_mean_absolute_error: 1.2611\n",
            "Epoch 192/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6216 - mean_absolute_error: 1.2547 - val_loss: 3.7434 - val_mean_absolute_error: 1.2516\n",
            "Epoch 193/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6533 - mean_absolute_error: 1.2540 - val_loss: 3.7469 - val_mean_absolute_error: 1.2998\n",
            "Epoch 194/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6319 - mean_absolute_error: 1.2572 - val_loss: 3.7412 - val_mean_absolute_error: 1.2536\n",
            "Epoch 195/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6199 - mean_absolute_error: 1.2548 - val_loss: 3.7404 - val_mean_absolute_error: 1.2678\n",
            "Epoch 196/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6351 - mean_absolute_error: 1.2514 - val_loss: 3.7395 - val_mean_absolute_error: 1.2612\n",
            "Epoch 197/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6355 - mean_absolute_error: 1.2555 - val_loss: 3.7416 - val_mean_absolute_error: 1.2519\n",
            "Epoch 198/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6237 - mean_absolute_error: 1.2538 - val_loss: 3.7407 - val_mean_absolute_error: 1.2646\n",
            "Epoch 199/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6172 - mean_absolute_error: 1.2531 - val_loss: 3.7404 - val_mean_absolute_error: 1.2485\n",
            "Epoch 200/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6194 - mean_absolute_error: 1.2506 - val_loss: 3.7403 - val_mean_absolute_error: 1.2493\n",
            "Epoch 201/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6326 - mean_absolute_error: 1.2525 - val_loss: 3.7368 - val_mean_absolute_error: 1.2599\n",
            "Epoch 202/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6300 - mean_absolute_error: 1.2577 - val_loss: 3.7405 - val_mean_absolute_error: 1.2809\n",
            "Epoch 203/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6219 - mean_absolute_error: 1.2546 - val_loss: 3.7382 - val_mean_absolute_error: 1.2593\n",
            "Epoch 204/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6192 - mean_absolute_error: 1.2527 - val_loss: 3.7387 - val_mean_absolute_error: 1.2746\n",
            "Epoch 205/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6274 - mean_absolute_error: 1.2514 - val_loss: 3.7365 - val_mean_absolute_error: 1.2579\n",
            "Epoch 206/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6249 - mean_absolute_error: 1.2516 - val_loss: 3.7362 - val_mean_absolute_error: 1.2694\n",
            "Epoch 207/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6293 - mean_absolute_error: 1.2518 - val_loss: 3.7369 - val_mean_absolute_error: 1.2791\n",
            "Epoch 208/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6227 - mean_absolute_error: 1.2530 - val_loss: 3.7348 - val_mean_absolute_error: 1.2545\n",
            "Epoch 209/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6128 - mean_absolute_error: 1.2502 - val_loss: 3.7348 - val_mean_absolute_error: 1.2758\n",
            "Epoch 210/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6128 - mean_absolute_error: 1.2521 - val_loss: 3.7401 - val_mean_absolute_error: 1.2839\n",
            "Epoch 211/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6076 - mean_absolute_error: 1.2508 - val_loss: 3.7344 - val_mean_absolute_error: 1.2572\n",
            "Epoch 212/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6111 - mean_absolute_error: 1.2500 - val_loss: 3.7353 - val_mean_absolute_error: 1.2492\n",
            "Epoch 213/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6015 - mean_absolute_error: 1.2483 - val_loss: 3.7336 - val_mean_absolute_error: 1.2630\n",
            "Epoch 214/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6112 - mean_absolute_error: 1.2521 - val_loss: 3.7331 - val_mean_absolute_error: 1.2594\n",
            "Epoch 215/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6016 - mean_absolute_error: 1.2486 - val_loss: 3.7326 - val_mean_absolute_error: 1.2644\n",
            "Epoch 216/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6061 - mean_absolute_error: 1.2504 - val_loss: 3.7320 - val_mean_absolute_error: 1.2685\n",
            "Epoch 217/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5871 - mean_absolute_error: 1.2516 - val_loss: 3.7316 - val_mean_absolute_error: 1.2534\n",
            "Epoch 218/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6059 - mean_absolute_error: 1.2506 - val_loss: 3.7320 - val_mean_absolute_error: 1.2515\n",
            "Epoch 219/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.6172 - mean_absolute_error: 1.2524 - val_loss: 3.7316 - val_mean_absolute_error: 1.2511\n",
            "Epoch 220/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6026 - mean_absolute_error: 1.2504 - val_loss: 3.7310 - val_mean_absolute_error: 1.2672\n",
            "Epoch 221/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5966 - mean_absolute_error: 1.2500 - val_loss: 3.7332 - val_mean_absolute_error: 1.2782\n",
            "Epoch 222/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.6065 - mean_absolute_error: 1.2490 - val_loss: 3.7299 - val_mean_absolute_error: 1.2565\n",
            "Epoch 223/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5973 - mean_absolute_error: 1.2496 - val_loss: 3.7306 - val_mean_absolute_error: 1.2517\n",
            "Epoch 224/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5888 - mean_absolute_error: 1.2471 - val_loss: 3.7290 - val_mean_absolute_error: 1.2645\n",
            "Epoch 225/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5974 - mean_absolute_error: 1.2488 - val_loss: 3.7303 - val_mean_absolute_error: 1.2705\n",
            "Epoch 226/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5889 - mean_absolute_error: 1.2492 - val_loss: 3.7301 - val_mean_absolute_error: 1.2526\n",
            "Epoch 227/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5931 - mean_absolute_error: 1.2473 - val_loss: 3.7291 - val_mean_absolute_error: 1.2600\n",
            "Epoch 228/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5701 - mean_absolute_error: 1.2466 - val_loss: 3.7295 - val_mean_absolute_error: 1.2476\n",
            "Epoch 229/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5938 - mean_absolute_error: 1.2483 - val_loss: 3.7283 - val_mean_absolute_error: 1.2582\n",
            "Epoch 230/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5849 - mean_absolute_error: 1.2474 - val_loss: 3.7282 - val_mean_absolute_error: 1.2544\n",
            "Epoch 231/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5911 - mean_absolute_error: 1.2464 - val_loss: 3.7286 - val_mean_absolute_error: 1.2549\n",
            "Epoch 232/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5853 - mean_absolute_error: 1.2441 - val_loss: 3.7282 - val_mean_absolute_error: 1.2535\n",
            "Epoch 233/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5782 - mean_absolute_error: 1.2464 - val_loss: 3.7287 - val_mean_absolute_error: 1.2507\n",
            "Epoch 234/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5902 - mean_absolute_error: 1.2488 - val_loss: 3.7291 - val_mean_absolute_error: 1.2503\n",
            "Epoch 235/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5786 - mean_absolute_error: 1.2482 - val_loss: 3.7267 - val_mean_absolute_error: 1.2691\n",
            "Epoch 236/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5880 - mean_absolute_error: 1.2487 - val_loss: 3.7273 - val_mean_absolute_error: 1.2579\n",
            "Epoch 237/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5758 - mean_absolute_error: 1.2468 - val_loss: 3.7271 - val_mean_absolute_error: 1.2671\n",
            "Epoch 238/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5734 - mean_absolute_error: 1.2482 - val_loss: 3.7299 - val_mean_absolute_error: 1.2676\n",
            "Epoch 239/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5805 - mean_absolute_error: 1.2446 - val_loss: 3.7262 - val_mean_absolute_error: 1.2526\n",
            "Epoch 240/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5788 - mean_absolute_error: 1.2445 - val_loss: 3.7258 - val_mean_absolute_error: 1.2665\n",
            "Epoch 241/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5648 - mean_absolute_error: 1.2483 - val_loss: 3.7262 - val_mean_absolute_error: 1.2574\n",
            "Epoch 242/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5485 - mean_absolute_error: 1.2470 - val_loss: 3.7294 - val_mean_absolute_error: 1.2414\n",
            "Epoch 243/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5621 - mean_absolute_error: 1.2458 - val_loss: 3.7260 - val_mean_absolute_error: 1.2621\n",
            "Epoch 244/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5762 - mean_absolute_error: 1.2473 - val_loss: 3.7257 - val_mean_absolute_error: 1.2643\n",
            "Epoch 245/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5715 - mean_absolute_error: 1.2473 - val_loss: 3.7257 - val_mean_absolute_error: 1.2676\n",
            "Epoch 246/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5723 - mean_absolute_error: 1.2474 - val_loss: 3.7309 - val_mean_absolute_error: 1.2746\n",
            "Epoch 247/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5677 - mean_absolute_error: 1.2418 - val_loss: 3.7273 - val_mean_absolute_error: 1.2420\n",
            "Epoch 248/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5670 - mean_absolute_error: 1.2454 - val_loss: 3.7258 - val_mean_absolute_error: 1.2535\n",
            "Epoch 249/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5409 - mean_absolute_error: 1.2465 - val_loss: 3.7287 - val_mean_absolute_error: 1.2756\n",
            "Epoch 250/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5590 - mean_absolute_error: 1.2434 - val_loss: 3.7270 - val_mean_absolute_error: 1.2592\n",
            "Epoch 251/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5616 - mean_absolute_error: 1.2460 - val_loss: 3.7274 - val_mean_absolute_error: 1.2743\n",
            "Epoch 252/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5630 - mean_absolute_error: 1.2468 - val_loss: 3.7277 - val_mean_absolute_error: 1.2431\n",
            "Epoch 253/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5606 - mean_absolute_error: 1.2421 - val_loss: 3.7244 - val_mean_absolute_error: 1.2593\n",
            "Epoch 254/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5580 - mean_absolute_error: 1.2469 - val_loss: 3.7262 - val_mean_absolute_error: 1.2494\n",
            "Epoch 255/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5557 - mean_absolute_error: 1.2431 - val_loss: 3.7281 - val_mean_absolute_error: 1.2415\n",
            "Epoch 256/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5392 - mean_absolute_error: 1.2433 - val_loss: 3.7299 - val_mean_absolute_error: 1.2360\n",
            "Epoch 257/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5683 - mean_absolute_error: 1.2474 - val_loss: 3.7284 - val_mean_absolute_error: 1.2693\n",
            "Epoch 258/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5363 - mean_absolute_error: 1.2434 - val_loss: 3.7287 - val_mean_absolute_error: 1.2621\n",
            "Epoch 259/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5478 - mean_absolute_error: 1.2421 - val_loss: 3.7267 - val_mean_absolute_error: 1.2516\n",
            "Epoch 260/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5587 - mean_absolute_error: 1.2419 - val_loss: 3.7253 - val_mean_absolute_error: 1.2558\n",
            "Epoch 261/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5404 - mean_absolute_error: 1.2451 - val_loss: 3.7313 - val_mean_absolute_error: 1.2717\n",
            "Epoch 262/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5538 - mean_absolute_error: 1.2416 - val_loss: 3.7274 - val_mean_absolute_error: 1.2727\n",
            "Epoch 263/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5475 - mean_absolute_error: 1.2452 - val_loss: 3.7308 - val_mean_absolute_error: 1.2832\n",
            "Epoch 264/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5410 - mean_absolute_error: 1.2411 - val_loss: 3.7269 - val_mean_absolute_error: 1.2516\n",
            "Epoch 265/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5366 - mean_absolute_error: 1.2456 - val_loss: 3.7246 - val_mean_absolute_error: 1.2634\n",
            "Epoch 266/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5442 - mean_absolute_error: 1.2427 - val_loss: 3.7259 - val_mean_absolute_error: 1.2708\n",
            "Epoch 267/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5377 - mean_absolute_error: 1.2436 - val_loss: 3.7253 - val_mean_absolute_error: 1.2641\n",
            "Epoch 268/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5353 - mean_absolute_error: 1.2427 - val_loss: 3.7250 - val_mean_absolute_error: 1.2522\n",
            "Epoch 269/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5373 - mean_absolute_error: 1.2443 - val_loss: 3.7277 - val_mean_absolute_error: 1.2738\n",
            "Epoch 270/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5450 - mean_absolute_error: 1.2430 - val_loss: 3.7257 - val_mean_absolute_error: 1.2661\n",
            "Epoch 271/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5222 - mean_absolute_error: 1.2413 - val_loss: 3.7257 - val_mean_absolute_error: 1.2552\n",
            "Epoch 272/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5233 - mean_absolute_error: 1.2407 - val_loss: 3.7259 - val_mean_absolute_error: 1.2697\n",
            "Epoch 273/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5451 - mean_absolute_error: 1.2408 - val_loss: 3.7237 - val_mean_absolute_error: 1.2561\n",
            "Epoch 274/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5294 - mean_absolute_error: 1.2423 - val_loss: 3.7252 - val_mean_absolute_error: 1.2471\n",
            "Epoch 275/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5251 - mean_absolute_error: 1.2412 - val_loss: 3.7237 - val_mean_absolute_error: 1.2591\n",
            "Epoch 276/500\n",
            "234/234 [==============================] - 1s 5ms/step - loss: 3.5244 - mean_absolute_error: 1.2395 - val_loss: 3.7236 - val_mean_absolute_error: 1.2710\n",
            "Epoch 277/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5330 - mean_absolute_error: 1.2442 - val_loss: 3.7277 - val_mean_absolute_error: 1.2553\n",
            "Epoch 278/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5250 - mean_absolute_error: 1.2422 - val_loss: 3.7233 - val_mean_absolute_error: 1.2473\n",
            "Epoch 279/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5294 - mean_absolute_error: 1.2414 - val_loss: 3.7262 - val_mean_absolute_error: 1.2473\n",
            "Epoch 280/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5419 - mean_absolute_error: 1.2406 - val_loss: 3.7259 - val_mean_absolute_error: 1.2500\n",
            "Epoch 281/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5273 - mean_absolute_error: 1.2380 - val_loss: 3.7246 - val_mean_absolute_error: 1.2559\n",
            "Epoch 282/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5362 - mean_absolute_error: 1.2447 - val_loss: 3.7248 - val_mean_absolute_error: 1.2470\n",
            "Epoch 283/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5292 - mean_absolute_error: 1.2405 - val_loss: 3.7245 - val_mean_absolute_error: 1.2538\n",
            "Epoch 284/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5127 - mean_absolute_error: 1.2379 - val_loss: 3.7245 - val_mean_absolute_error: 1.2549\n",
            "Epoch 285/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5126 - mean_absolute_error: 1.2400 - val_loss: 3.7255 - val_mean_absolute_error: 1.2471\n",
            "Epoch 286/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5258 - mean_absolute_error: 1.2417 - val_loss: 3.7254 - val_mean_absolute_error: 1.2581\n",
            "Epoch 287/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5263 - mean_absolute_error: 1.2388 - val_loss: 3.7266 - val_mean_absolute_error: 1.2682\n",
            "Epoch 288/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5129 - mean_absolute_error: 1.2402 - val_loss: 3.7281 - val_mean_absolute_error: 1.2437\n",
            "Epoch 289/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5183 - mean_absolute_error: 1.2385 - val_loss: 3.7248 - val_mean_absolute_error: 1.2638\n",
            "Epoch 290/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5209 - mean_absolute_error: 1.2398 - val_loss: 3.7348 - val_mean_absolute_error: 1.3008\n",
            "Epoch 291/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5264 - mean_absolute_error: 1.2412 - val_loss: 3.7290 - val_mean_absolute_error: 1.2696\n",
            "Epoch 292/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.4940 - mean_absolute_error: 1.2401 - val_loss: 3.7337 - val_mean_absolute_error: 1.2802\n",
            "Epoch 293/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5110 - mean_absolute_error: 1.2373 - val_loss: 3.7266 - val_mean_absolute_error: 1.2559\n",
            "Epoch 294/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5156 - mean_absolute_error: 1.2418 - val_loss: 3.7276 - val_mean_absolute_error: 1.2636\n",
            "Epoch 295/500\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "234/234 [==============================] - 1s 4ms/step - loss: 3.4988 - mean_absolute_error: 1.2371 - val_loss: 3.7267 - val_mean_absolute_error: 1.2642\n",
            "Epoch 296/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5084 - mean_absolute_error: 1.2416 - val_loss: 3.7277 - val_mean_absolute_error: 1.2704\n",
            "Epoch 297/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5108 - mean_absolute_error: 1.2392 - val_loss: 3.7304 - val_mean_absolute_error: 1.2745\n",
            "Epoch 298/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5006 - mean_absolute_error: 1.2388 - val_loss: 3.7270 - val_mean_absolute_error: 1.2632\n",
            "Epoch 299/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.4966 - mean_absolute_error: 1.2407 - val_loss: 3.7284 - val_mean_absolute_error: 1.2623\n",
            "Epoch 300/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.4949 - mean_absolute_error: 1.2383 - val_loss: 3.7253 - val_mean_absolute_error: 1.2699\n",
            "Epoch 301/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.4991 - mean_absolute_error: 1.2406 - val_loss: 3.7301 - val_mean_absolute_error: 1.2418\n",
            "Epoch 302/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5002 - mean_absolute_error: 1.2374 - val_loss: 3.7329 - val_mean_absolute_error: 1.2354\n",
            "Epoch 303/500\n",
            "234/234 [==============================] - 1s 4ms/step - loss: 3.5015 - mean_absolute_error: 1.2369 - val_loss: 3.7249 - val_mean_absolute_error: 1.2604\n"
          ]
        }
      ],
      "source": [
        "print('\\nFitting DNN (Retrieval Module - Rain):\\n')\n",
        "batch_size2 = 600\n",
        "history_retrieval_rain = model_retrieval_rain.fit(Xf_rain_trn_retrieval, yf_rain_trn_retrieval, epochs=500,\n",
        "                                validation_split=.2, batch_size = batch_size2,\n",
        "                                callbacks=callbacks_list, verbose=1)"
      ],
      "id": "vtYqGaYIPtfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTKgVbr5Ptfx",
        "outputId": "89db3158-3b0a-4ed1-d55d-f8ef48c81730"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x194b404d6d0>"
            ]
          },
          "execution_count": 44,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "val_loss = history_retrieval_rain.history[\"val_loss\"]\n",
        "loss = history_retrieval_rain.history[\"loss\"]\n",
        "\n",
        "epochs = range(1, 304)\n",
        "plt.plot(epochs, val_loss[:], \"r-\",\n",
        "label=\"Validation Loss\")\n",
        "plt.plot(epochs, loss[:], \"b-\",\n",
        "label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "id": "gTKgVbr5Ptfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sAv6xetxPtfx"
      },
      "outputs": [],
      "source": [
        "predictions_rain = model_retrieval_rain.predict(Xf_rain_tst_retrieval)"
      ],
      "id": "sAv6xetxPtfx"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH3u4lp8Ptfy",
        "outputId": "1eb52b79-1b25-4732-bd7c-524840ba52e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "125/125 [==============================] - 0s 862us/step - loss: 3.9410 - mean_absolute_error: 1.3309\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[3.941049098968506, 1.3308517932891846]"
            ]
          },
          "execution_count": 46,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_retrieval_rain.evaluate(Xf_rain_tst_retrieval, yf_rain_tst_retrieval, batch_size = batch_size2)"
      ],
      "id": "oH3u4lp8Ptfy"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-O8XJOpPtfy"
      },
      "source": [
        "# **3. Saving the models**"
      ],
      "id": "e-O8XJOpPtfy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fjvlyT55Ptfz"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy.io import savemat\n",
        "\n",
        "model_detection.save('Models\\DPR\\Coast\\model_dtc',save_format='h5')\n",
        "model_retrieval_snow.save('Models\\DPR\\Coast\\model_snow',save_format='h5')\n",
        "model_retrieval_rain.save('Models\\DPR\\Coast\\model_rain',save_format='h5')\n",
        "\n",
        "fp_DPR_coast = 'Models/DPR/coast/files_DPR_coast.mat'\n",
        "scipy.io.savemat(fp_DPR_coast, {'mean_detection_DPR_coast': mean_detection,'std_detection_DPR_coast':std_detection,\n",
        "                               'mean_snow_retrieval_DPR_coast': mean_snow_retrieval,'std_snow_retrieval_DPR_coast':std_snow_retrieval,\n",
        "                               'mean_rain_retrieval_DPR_coast': mean_rain_retrieval,'std_rain_retrieval_DPR_coast':std_rain_retrieval})\n"
      ],
      "id": "fjvlyT55Ptfz"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}