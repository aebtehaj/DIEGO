{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#**Training d-DNN and e-DNNs using CPR coincidences over the land**"
      ],
      "metadata": {
        "id": "dAUlqvwPUcrl"
      },
      "id": "dAUlqvwPUcrl"
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.io import loadmat\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import h5py\n",
        "import os"
      ],
      "metadata": {
        "id": "KQjTIyPHUgrO"
      },
      "id": "KQjTIyPHUgrO",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1. Data**"
      ],
      "metadata": {
        "id": "9M6PbdNlWZh-"
      },
      "id": "9M6PbdNlWZh-"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.1 Data Loading and Organizing**"
      ],
      "metadata": {
        "id": "CsrYbBeRWaIe"
      },
      "id": "CsrYbBeRWaIe"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K4lmXyViTEaq",
        "outputId": "5472af04-8c3d-48a8-a2ac-6963c84846f6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['X_land_trn_detection',\n",
              " 'X_land_trn_retrieval',\n",
              " 'X_land_tst_detection',\n",
              " 'X_land_tst_retrieval',\n",
              " 'y_land_trn_detection',\n",
              " 'y_land_trn_retrieval',\n",
              " 'y_land_tst_detection',\n",
              " 'y_land_tst_retrieval']"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "f = h5py.File('Data/Dictionaries/Dic_CPR_land.mat','r')\n",
        "list(f.keys())"
      ],
      "id": "K4lmXyViTEaq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RVT4XzFNTEar"
      },
      "outputs": [],
      "source": [
        "X1_trn_detection = np.transpose(f['X_land_trn_detection'])\n",
        "y_trn_detection = np.transpose(f['y_land_trn_detection'])\n",
        "X1_tst_detection = np.transpose(f['X_land_tst_detection'])\n",
        "y_tst_detection = np.transpose(f['y_land_tst_detection'])\n",
        "\n",
        "X1_trn_retrieval = np.transpose(f['X_land_trn_retrieval'])\n",
        "y_trn_retrieval = np.transpose(f['y_land_trn_retrieval'])\n",
        "X1_tst_retrieval = np.transpose(f['X_land_tst_retrieval'])\n",
        "y_tst_retrieval = np.transpose(f['y_land_tst_retrieval'])"
      ],
      "id": "RVT4XzFNTEar"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "64EeO793TEas"
      },
      "outputs": [],
      "source": [
        "X1_trn_detection.astype('float64')\n",
        "X1_tst_detection.astype('float64')\n",
        "y_trn_detection.astype('int64')\n",
        "y_tst_detection.astype('int64')\n",
        "\n",
        "X1_trn_retrieval.astype('float64')\n",
        "X1_tst_retrieval.astype('float64')\n",
        "y_trn_retrieval.astype('float64')\n",
        "y_tst_retrieval.astype('float64');"
      ],
      "id": "64EeO793TEas"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **1.2 Data Normalizing**\n",
        "\n",
        "The input features for training have different ranges and units, therefore they need to be scaled to make the flow of the gradient decsent smooth and help the algorithm quickly reaches the optimal point of the cost function. Without scaling features, the algorithm may be biased toward those features which have larger magnitues. We used the following standardization:\n",
        "\n",
        "$X_i^{\\prime} = \\frac{X_i - \\mu}{σ}$\n",
        "\n",
        "In the above equation $X_i^{\\prime}$ is the scaled feature, $μ$ is the mean, and $σ$ is the standard deviation of the feature. In the next cell, we implement this scaling for the data sets."
      ],
      "metadata": {
        "id": "7SwcvL06TvgO"
      },
      "id": "7SwcvL06TvgO"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NdpKA9exTEas"
      },
      "outputs": [],
      "source": [
        "mean_detection = X1_trn_detection.mean(axis=0)\n",
        "X2_trn_detection = X1_trn_detection-mean_detection\n",
        "std_detection = X1_trn_detection.std(axis=0)\n",
        "X_trn_detection = X2_trn_detection/std_detection\n",
        "X2_tst_detection = X1_tst_detection-mean_detection\n",
        "X_tst_detection = X2_tst_detection/std_detection\n",
        "\n",
        "mean_retrieval = X1_trn_retrieval.mean(axis=0)\n",
        "X2_trn_retrieval = X1_trn_retrieval-mean_retrieval\n",
        "std_retrieval = X1_trn_retrieval.std(axis=0)\n",
        "X_trn_retrieval = X2_trn_retrieval/std_retrieval\n",
        "X2_tst_retrieval = X1_tst_retrieval-mean_retrieval\n",
        "X_tst_retrieval = X2_tst_retrieval/std_retrieval"
      ],
      "id": "NdpKA9exTEas"
    },
    {
      "cell_type": "markdown",
      "source": [
        "To show that the labels are balanced in the training and test set, the number of snowfall, rainfall and no precipitation lables is printed in the next cell."
      ],
      "metadata": {
        "id": "Dwvj37OUUDBd"
      },
      "id": "Dwvj37OUUDBd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e4UeQOfPTEas",
        "outputId": "2320fd67-b381-4810-e6f7-7a33f564611f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "***Training Dataset:\n",
            "\n",
            "Num. of snowfall: 54466\n",
            "Num. of rainfall: 54601\n",
            "Num. of clear-sky: 108770\n",
            "\n",
            "***Testing Dataset:\n",
            "\n",
            "Num. of snowfall: 23338\n",
            "Num. of rainfall: 23203\n",
            "Num. of clear-sky: 46816\n"
          ]
        }
      ],
      "source": [
        "print('***Training Dataset:\\n')\n",
        "\n",
        "n_snow=1\n",
        "n_rain=1\n",
        "n_clear=1  \n",
        "t_train = np.zeros([y_trn_detection.shape[0],1])\n",
        "\n",
        "for i in range(len(X_trn_detection)):\n",
        "    label = y_trn_detection[i]\n",
        "    if label==5:\n",
        "        n_snow+=1\n",
        "        t_train[i]=2\n",
        "    if label==3:\n",
        "        n_rain+=1  \n",
        "        t_train[i]=1\n",
        "    if label==0:\n",
        "        n_clear+=1\n",
        "        t_train[i]=0\n",
        "        \n",
        "print('Num. of snowfall:',n_snow)\n",
        "print('Num. of rainfall:',n_rain)\n",
        "print('Num. of clear-sky:',n_clear)\n",
        "\n",
        "print('\\n***Testing Dataset:\\n')\n",
        "\n",
        "n_snow=1\n",
        "n_rain=1\n",
        "n_clear=1  \n",
        "t_test = np.zeros([y_tst_detection.shape[0],1])\n",
        "\n",
        "for i in range(len(X_tst_detection)):\n",
        "    label = y_tst_detection[i]\n",
        "    if label==5:\n",
        "        n_snow+=1\n",
        "        t_test[i]=2\n",
        "    if label==3:\n",
        "        n_rain+=1  \n",
        "        t_test[i]=1\n",
        "    if label==0:\n",
        "        n_clear+=1\n",
        "        t_test[i]=0\n",
        "        \n",
        "print('Num. of snowfall:',n_snow)\n",
        "print('Num. of rainfall:',n_rain)\n",
        "print('Num. of clear-sky:',n_clear)"
      ],
      "id": "e4UeQOfPTEas"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GniXvk8HTEat"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "t_trn_detection = to_categorical(t_train)\n",
        "t_tst_detection = to_categorical(t_test)"
      ],
      "id": "GniXvk8HTEat"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryrpnJ_aTEat"
      },
      "source": [
        "# **2. Training the networks**\n"
      ],
      "id": "ryrpnJ_aTEat"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **2.1 - Detection Network (d-DNN)**"
      ],
      "metadata": {
        "id": "3EfsniCvWs_o"
      },
      "id": "3EfsniCvWs_o"
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "Jv1LQfL8TEau"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
        "from tensorflow.keras.layers import BatchNormalization\n",
        "from tensorflow.keras import layers, Sequential"
      ],
      "id": "Jv1LQfL8TEau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oAdSQd2GTEau"
      },
      "outputs": [],
      "source": [
        "# Defining the architecture of the d-DNN network which has 6 layers and 30 hidden units in each layer.\n",
        "\n",
        "# Parameters\n",
        "hidden_units = 30\n",
        "dropout = 0\n",
        "\n",
        "# Detection Module\n",
        "model_detection = Sequential()\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(hidden_units))\n",
        "model_detection.add(Activation('relu'))\n",
        "model_detection.add(Dropout(dropout))\n",
        "\n",
        "model_detection.add(Dense(3))\n",
        "model_detection.add(Activation('softmax'))"
      ],
      "id": "oAdSQd2GTEau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PMkT1E5KTEau"
      },
      "outputs": [],
      "source": [
        "# Compiling the model by defining the loss function and learning rate.\n",
        "\n",
        "model_detection.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.0001),\n",
        "              loss = 'categorical_crossentropy',\n",
        "              metrics= [tf.keras.metrics.Recall()])"
      ],
      "id": "PMkT1E5KTEau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4kQ-DFQWTEau"
      },
      "outputs": [],
      "source": [
        "# Defining the callback list for early stoping and saving the model.\n",
        "from tensorflow import keras\n",
        "callbacks_list = [\n",
        "#     keras.callbacks.EarlyStopping(\n",
        "#     monitor=\"val_loss\",\n",
        "#     patience=25,),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint_path.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    save_best_only=True,\n",
        "    )    \n",
        "]"
      ],
      "id": "4kQ-DFQWTEau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhfuF8vYTEau",
        "outputId": "0b550b84-4b8b-4aa3-a2c7-6c6ceaa0c398"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Fitting DNN (Detection Module):\n",
            "\n",
            "Epoch 1/400\n",
            "349/349 [==============================] - 26s 19ms/step - loss: 0.8632 - recall_2: 0.2567 - val_loss: 0.6195 - val_recall_2: 0.4771\n",
            "Epoch 2/400\n",
            "349/349 [==============================] - 3s 9ms/step - loss: 0.4564 - recall_2: 0.7057 - val_loss: 0.3372 - val_recall_2: 0.8499\n",
            "Epoch 3/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.2826 - recall_2: 0.8803 - val_loss: 0.2304 - val_recall_2: 0.8971\n",
            "Epoch 4/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.2108 - recall_2: 0.9093 - val_loss: 0.1931 - val_recall_2: 0.9202\n",
            "Epoch 5/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1867 - recall_2: 0.9225 - val_loss: 0.1772 - val_recall_2: 0.9248\n",
            "Epoch 6/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1748 - recall_2: 0.9266 - val_loss: 0.1701 - val_recall_2: 0.9296\n",
            "Epoch 7/400\n",
            "349/349 [==============================] - 3s 9ms/step - loss: 0.1675 - recall_2: 0.9299 - val_loss: 0.1630 - val_recall_2: 0.9314\n",
            "Epoch 8/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1626 - recall_2: 0.9319 - val_loss: 0.1594 - val_recall_2: 0.9319\n",
            "Epoch 9/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1591 - recall_2: 0.9346 - val_loss: 0.1559 - val_recall_2: 0.9350\n",
            "Epoch 10/400\n",
            "349/349 [==============================] - 3s 7ms/step - loss: 0.1561 - recall_2: 0.9356 - val_loss: 0.1547 - val_recall_2: 0.9362\n",
            "Epoch 11/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1539 - recall_2: 0.9364 - val_loss: 0.1529 - val_recall_2: 0.9350\n",
            "Epoch 12/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1524 - recall_2: 0.9370 - val_loss: 0.1516 - val_recall_2: 0.9377\n",
            "Epoch 13/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1509 - recall_2: 0.9374 - val_loss: 0.1499 - val_recall_2: 0.9364\n",
            "Epoch 14/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1496 - recall_2: 0.9377 - val_loss: 0.1482 - val_recall_2: 0.9381\n",
            "Epoch 15/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1484 - recall_2: 0.9386 - val_loss: 0.1473 - val_recall_2: 0.9386\n",
            "Epoch 16/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1474 - recall_2: 0.9387 - val_loss: 0.1469 - val_recall_2: 0.9392\n",
            "Epoch 17/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1466 - recall_2: 0.9387 - val_loss: 0.1458 - val_recall_2: 0.9400\n",
            "Epoch 18/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1457 - recall_2: 0.9395 - val_loss: 0.1448 - val_recall_2: 0.9398\n",
            "Epoch 19/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1449 - recall_2: 0.9399 - val_loss: 0.1461 - val_recall_2: 0.9399\n",
            "Epoch 20/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1442 - recall_2: 0.9400 - val_loss: 0.1448 - val_recall_2: 0.9404\n",
            "Epoch 21/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1436 - recall_2: 0.9402 - val_loss: 0.1433 - val_recall_2: 0.9407\n",
            "Epoch 22/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1428 - recall_2: 0.9407 - val_loss: 0.1423 - val_recall_2: 0.9409\n",
            "Epoch 23/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1422 - recall_2: 0.9407 - val_loss: 0.1422 - val_recall_2: 0.9411\n",
            "Epoch 24/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1415 - recall_2: 0.9410 - val_loss: 0.1414 - val_recall_2: 0.9405\n",
            "Epoch 25/400\n",
            "349/349 [==============================] - 3s 7ms/step - loss: 0.1408 - recall_2: 0.9412 - val_loss: 0.1405 - val_recall_2: 0.9415\n",
            "Epoch 26/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1401 - recall_2: 0.9419 - val_loss: 0.1401 - val_recall_2: 0.9421\n",
            "Epoch 27/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1397 - recall_2: 0.9418 - val_loss: 0.1445 - val_recall_2: 0.9396\n",
            "Epoch 28/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1390 - recall_2: 0.9425 - val_loss: 0.1408 - val_recall_2: 0.9419\n",
            "Epoch 29/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1385 - recall_2: 0.9425 - val_loss: 0.1405 - val_recall_2: 0.9419\n",
            "Epoch 30/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1379 - recall_2: 0.9430 - val_loss: 0.1384 - val_recall_2: 0.9431\n",
            "Epoch 31/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1373 - recall_2: 0.9433 - val_loss: 0.1381 - val_recall_2: 0.9431\n",
            "Epoch 32/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1370 - recall_2: 0.9436 - val_loss: 0.1377 - val_recall_2: 0.9434\n",
            "Epoch 33/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1364 - recall_2: 0.9437 - val_loss: 0.1389 - val_recall_2: 0.9427\n",
            "Epoch 34/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1359 - recall_2: 0.9445 - val_loss: 0.1381 - val_recall_2: 0.9431\n",
            "Epoch 35/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1356 - recall_2: 0.9447 - val_loss: 0.1364 - val_recall_2: 0.9444\n",
            "Epoch 36/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1352 - recall_2: 0.9448 - val_loss: 0.1366 - val_recall_2: 0.9443\n",
            "Epoch 37/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1347 - recall_2: 0.9454 - val_loss: 0.1366 - val_recall_2: 0.9443\n",
            "Epoch 38/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1343 - recall_2: 0.9454 - val_loss: 0.1364 - val_recall_2: 0.9441\n",
            "Epoch 39/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1340 - recall_2: 0.9456 - val_loss: 0.1347 - val_recall_2: 0.9451\n",
            "Epoch 40/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1336 - recall_2: 0.9457 - val_loss: 0.1348 - val_recall_2: 0.9452\n",
            "Epoch 41/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1330 - recall_2: 0.9458 - val_loss: 0.1344 - val_recall_2: 0.9450\n",
            "Epoch 42/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1327 - recall_2: 0.9462 - val_loss: 0.1339 - val_recall_2: 0.9450\n",
            "Epoch 43/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1324 - recall_2: 0.9463 - val_loss: 0.1375 - val_recall_2: 0.9429\n",
            "Epoch 44/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1321 - recall_2: 0.9466 - val_loss: 0.1339 - val_recall_2: 0.9455\n",
            "Epoch 45/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1317 - recall_2: 0.9469 - val_loss: 0.1331 - val_recall_2: 0.9457\n",
            "Epoch 46/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1313 - recall_2: 0.9469 - val_loss: 0.1348 - val_recall_2: 0.9449\n",
            "Epoch 47/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1311 - recall_2: 0.9468 - val_loss: 0.1326 - val_recall_2: 0.9459\n",
            "Epoch 48/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1307 - recall_2: 0.9472 - val_loss: 0.1330 - val_recall_2: 0.9457\n",
            "Epoch 49/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1303 - recall_2: 0.9471 - val_loss: 0.1323 - val_recall_2: 0.9462\n",
            "Epoch 50/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1302 - recall_2: 0.9474 - val_loss: 0.1332 - val_recall_2: 0.9460\n",
            "Epoch 51/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1298 - recall_2: 0.9476 - val_loss: 0.1320 - val_recall_2: 0.9466\n",
            "Epoch 52/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1295 - recall_2: 0.9476 - val_loss: 0.1359 - val_recall_2: 0.9439\n",
            "Epoch 53/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1293 - recall_2: 0.9477 - val_loss: 0.1314 - val_recall_2: 0.9465\n",
            "Epoch 54/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1290 - recall_2: 0.9478 - val_loss: 0.1309 - val_recall_2: 0.9468\n",
            "Epoch 55/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1286 - recall_2: 0.9482 - val_loss: 0.1307 - val_recall_2: 0.9471\n",
            "Epoch 56/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1283 - recall_2: 0.9478 - val_loss: 0.1305 - val_recall_2: 0.9470\n",
            "Epoch 57/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1279 - recall_2: 0.9485 - val_loss: 0.1303 - val_recall_2: 0.9472\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 58/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1278 - recall_2: 0.9483 - val_loss: 0.1301 - val_recall_2: 0.9473\n",
            "Epoch 59/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1274 - recall_2: 0.9484 - val_loss: 0.1302 - val_recall_2: 0.9473\n",
            "Epoch 60/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1271 - recall_2: 0.9487 - val_loss: 0.1296 - val_recall_2: 0.9474\n",
            "Epoch 61/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1268 - recall_2: 0.9484 - val_loss: 0.1309 - val_recall_2: 0.9462\n",
            "Epoch 62/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1265 - recall_2: 0.9487 - val_loss: 0.1295 - val_recall_2: 0.9469\n",
            "Epoch 63/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1263 - recall_2: 0.9488 - val_loss: 0.1296 - val_recall_2: 0.9471\n",
            "Epoch 64/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1260 - recall_2: 0.9489 - val_loss: 0.1290 - val_recall_2: 0.9480\n",
            "Epoch 65/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1257 - recall_2: 0.9489 - val_loss: 0.1282 - val_recall_2: 0.9482\n",
            "Epoch 66/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1255 - recall_2: 0.9492 - val_loss: 0.1283 - val_recall_2: 0.9484\n",
            "Epoch 67/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1252 - recall_2: 0.9491 - val_loss: 0.1285 - val_recall_2: 0.9478\n",
            "Epoch 68/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1250 - recall_2: 0.9496 - val_loss: 0.1291 - val_recall_2: 0.9476\n",
            "Epoch 69/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1247 - recall_2: 0.9498 - val_loss: 0.1281 - val_recall_2: 0.9480\n",
            "Epoch 70/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1243 - recall_2: 0.9495 - val_loss: 0.1274 - val_recall_2: 0.9485\n",
            "Epoch 71/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1241 - recall_2: 0.9500 - val_loss: 0.1271 - val_recall_2: 0.9488\n",
            "Epoch 72/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1238 - recall_2: 0.9502 - val_loss: 0.1275 - val_recall_2: 0.9484\n",
            "Epoch 73/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1236 - recall_2: 0.9500 - val_loss: 0.1275 - val_recall_2: 0.9486\n",
            "Epoch 74/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1234 - recall_2: 0.9503 - val_loss: 0.1267 - val_recall_2: 0.9486\n",
            "Epoch 75/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1231 - recall_2: 0.9503 - val_loss: 0.1277 - val_recall_2: 0.9483\n",
            "Epoch 76/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1228 - recall_2: 0.9506 - val_loss: 0.1266 - val_recall_2: 0.9488\n",
            "Epoch 77/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1227 - recall_2: 0.9506 - val_loss: 0.1260 - val_recall_2: 0.9490\n",
            "Epoch 78/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1223 - recall_2: 0.9504 - val_loss: 0.1277 - val_recall_2: 0.9479\n",
            "Epoch 79/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1221 - recall_2: 0.9505 - val_loss: 0.1256 - val_recall_2: 0.9486\n",
            "Epoch 80/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1219 - recall_2: 0.9506 - val_loss: 0.1262 - val_recall_2: 0.9491\n",
            "Epoch 81/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1219 - recall_2: 0.9510 - val_loss: 0.1265 - val_recall_2: 0.9484\n",
            "Epoch 82/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1215 - recall_2: 0.9507 - val_loss: 0.1257 - val_recall_2: 0.9491\n",
            "Epoch 83/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1214 - recall_2: 0.9509 - val_loss: 0.1257 - val_recall_2: 0.9491\n",
            "Epoch 84/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1212 - recall_2: 0.9510 - val_loss: 0.1258 - val_recall_2: 0.9489\n",
            "Epoch 85/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1209 - recall_2: 0.9512 - val_loss: 0.1254 - val_recall_2: 0.9486\n",
            "Epoch 86/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1207 - recall_2: 0.9512 - val_loss: 0.1285 - val_recall_2: 0.9468\n",
            "Epoch 87/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1206 - recall_2: 0.9510 - val_loss: 0.1256 - val_recall_2: 0.9490\n",
            "Epoch 88/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1205 - recall_2: 0.9516 - val_loss: 0.1254 - val_recall_2: 0.9495\n",
            "Epoch 89/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1200 - recall_2: 0.9511 - val_loss: 0.1279 - val_recall_2: 0.9473\n",
            "Epoch 90/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1199 - recall_2: 0.9514 - val_loss: 0.1249 - val_recall_2: 0.9491\n",
            "Epoch 91/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1197 - recall_2: 0.9512 - val_loss: 0.1245 - val_recall_2: 0.9492\n",
            "Epoch 92/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1195 - recall_2: 0.9514 - val_loss: 0.1298 - val_recall_2: 0.9481\n",
            "Epoch 93/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1193 - recall_2: 0.9517 - val_loss: 0.1241 - val_recall_2: 0.9492\n",
            "Epoch 94/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1192 - recall_2: 0.9517 - val_loss: 0.1238 - val_recall_2: 0.9497\n",
            "Epoch 95/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1189 - recall_2: 0.9518 - val_loss: 0.1250 - val_recall_2: 0.9489\n",
            "Epoch 96/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1187 - recall_2: 0.9518 - val_loss: 0.1248 - val_recall_2: 0.9490\n",
            "Epoch 97/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1185 - recall_2: 0.9518 - val_loss: 0.1248 - val_recall_2: 0.9493\n",
            "Epoch 98/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1184 - recall_2: 0.9519 - val_loss: 0.1241 - val_recall_2: 0.9497\n",
            "Epoch 99/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1184 - recall_2: 0.9521 - val_loss: 0.1234 - val_recall_2: 0.9502\n",
            "Epoch 100/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1181 - recall_2: 0.9521 - val_loss: 0.1232 - val_recall_2: 0.9499\n",
            "Epoch 101/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1179 - recall_2: 0.9521 - val_loss: 0.1232 - val_recall_2: 0.9508\n",
            "Epoch 102/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1179 - recall_2: 0.9523 - val_loss: 0.1245 - val_recall_2: 0.9494\n",
            "Epoch 103/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1175 - recall_2: 0.9525 - val_loss: 0.1233 - val_recall_2: 0.9502\n",
            "Epoch 104/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1174 - recall_2: 0.9527 - val_loss: 0.1235 - val_recall_2: 0.9499\n",
            "Epoch 105/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1172 - recall_2: 0.9526 - val_loss: 0.1240 - val_recall_2: 0.9505\n",
            "Epoch 106/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1171 - recall_2: 0.9526 - val_loss: 0.1232 - val_recall_2: 0.9512\n",
            "Epoch 107/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1171 - recall_2: 0.9527 - val_loss: 0.1239 - val_recall_2: 0.9508\n",
            "Epoch 108/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1169 - recall_2: 0.9529 - val_loss: 0.1225 - val_recall_2: 0.9508\n",
            "Epoch 109/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1167 - recall_2: 0.9529 - val_loss: 0.1225 - val_recall_2: 0.9508\n",
            "Epoch 110/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1164 - recall_2: 0.9530 - val_loss: 0.1239 - val_recall_2: 0.9502\n",
            "Epoch 111/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1163 - recall_2: 0.9531 - val_loss: 0.1241 - val_recall_2: 0.9507\n",
            "Epoch 112/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1161 - recall_2: 0.9532 - val_loss: 0.1223 - val_recall_2: 0.9513\n",
            "Epoch 113/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1161 - recall_2: 0.9533 - val_loss: 0.1224 - val_recall_2: 0.9518\n",
            "Epoch 114/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1158 - recall_2: 0.9531 - val_loss: 0.1274 - val_recall_2: 0.9476\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 115/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1158 - recall_2: 0.9532 - val_loss: 0.1221 - val_recall_2: 0.9514\n",
            "Epoch 116/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1156 - recall_2: 0.9536 - val_loss: 0.1214 - val_recall_2: 0.9518\n",
            "Epoch 117/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1155 - recall_2: 0.9532 - val_loss: 0.1212 - val_recall_2: 0.9518\n",
            "Epoch 118/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1153 - recall_2: 0.9535 - val_loss: 0.1215 - val_recall_2: 0.9511\n",
            "Epoch 119/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1150 - recall_2: 0.9538 - val_loss: 0.1263 - val_recall_2: 0.9484\n",
            "Epoch 120/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1150 - recall_2: 0.9534 - val_loss: 0.1212 - val_recall_2: 0.9520\n",
            "Epoch 121/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1150 - recall_2: 0.9538 - val_loss: 0.1215 - val_recall_2: 0.9515\n",
            "Epoch 122/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1148 - recall_2: 0.9537 - val_loss: 0.1257 - val_recall_2: 0.9479\n",
            "Epoch 123/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1148 - recall_2: 0.9537 - val_loss: 0.1219 - val_recall_2: 0.9515\n",
            "Epoch 124/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1146 - recall_2: 0.9538 - val_loss: 0.1217 - val_recall_2: 0.9521\n",
            "Epoch 125/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1143 - recall_2: 0.9540 - val_loss: 0.1224 - val_recall_2: 0.9514\n",
            "Epoch 126/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1142 - recall_2: 0.9538 - val_loss: 0.1222 - val_recall_2: 0.9510\n",
            "Epoch 127/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1142 - recall_2: 0.9541 - val_loss: 0.1212 - val_recall_2: 0.9516\n",
            "Epoch 128/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1140 - recall_2: 0.9541 - val_loss: 0.1212 - val_recall_2: 0.9520\n",
            "Epoch 129/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1139 - recall_2: 0.9542 - val_loss: 0.1213 - val_recall_2: 0.9517\n",
            "Epoch 130/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1138 - recall_2: 0.9538 - val_loss: 0.1210 - val_recall_2: 0.9519\n",
            "Epoch 131/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1136 - recall_2: 0.9546 - val_loss: 0.1246 - val_recall_2: 0.9506\n",
            "Epoch 132/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1136 - recall_2: 0.9546 - val_loss: 0.1217 - val_recall_2: 0.9509\n",
            "Epoch 133/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1133 - recall_2: 0.9545 - val_loss: 0.1199 - val_recall_2: 0.9528\n",
            "Epoch 134/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1133 - recall_2: 0.9546 - val_loss: 0.1221 - val_recall_2: 0.9505\n",
            "Epoch 135/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1132 - recall_2: 0.9546 - val_loss: 0.1206 - val_recall_2: 0.9522\n",
            "Epoch 136/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1130 - recall_2: 0.9550 - val_loss: 0.1202 - val_recall_2: 0.9526\n",
            "Epoch 137/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1129 - recall_2: 0.9550 - val_loss: 0.1279 - val_recall_2: 0.9472\n",
            "Epoch 138/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1128 - recall_2: 0.9549 - val_loss: 0.1216 - val_recall_2: 0.9517\n",
            "Epoch 139/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1127 - recall_2: 0.9547 - val_loss: 0.1200 - val_recall_2: 0.9527\n",
            "Epoch 140/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1126 - recall_2: 0.9548 - val_loss: 0.1206 - val_recall_2: 0.9523\n",
            "Epoch 141/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1125 - recall_2: 0.9551 - val_loss: 0.1211 - val_recall_2: 0.9515\n",
            "Epoch 142/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1124 - recall_2: 0.9549 - val_loss: 0.1207 - val_recall_2: 0.9526\n",
            "Epoch 143/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1122 - recall_2: 0.9551 - val_loss: 0.1196 - val_recall_2: 0.9528\n",
            "Epoch 144/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1121 - recall_2: 0.9549 - val_loss: 0.1228 - val_recall_2: 0.9505\n",
            "Epoch 145/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1122 - recall_2: 0.9553 - val_loss: 0.1200 - val_recall_2: 0.9526\n",
            "Epoch 146/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1119 - recall_2: 0.9552 - val_loss: 0.1212 - val_recall_2: 0.9517\n",
            "Epoch 147/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1118 - recall_2: 0.9555 - val_loss: 0.1214 - val_recall_2: 0.9515\n",
            "Epoch 148/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1120 - recall_2: 0.9554 - val_loss: 0.1256 - val_recall_2: 0.9515\n",
            "Epoch 149/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1117 - recall_2: 0.9554 - val_loss: 0.1196 - val_recall_2: 0.9529\n",
            "Epoch 150/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1116 - recall_2: 0.9556 - val_loss: 0.1201 - val_recall_2: 0.9532\n",
            "Epoch 151/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1115 - recall_2: 0.9555 - val_loss: 0.1204 - val_recall_2: 0.9525\n",
            "Epoch 152/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1114 - recall_2: 0.9552 - val_loss: 0.1201 - val_recall_2: 0.9530\n",
            "Epoch 153/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1113 - recall_2: 0.9557 - val_loss: 0.1232 - val_recall_2: 0.9508\n",
            "Epoch 154/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1112 - recall_2: 0.9555 - val_loss: 0.1195 - val_recall_2: 0.9535\n",
            "Epoch 155/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1110 - recall_2: 0.9558 - val_loss: 0.1196 - val_recall_2: 0.9534\n",
            "Epoch 156/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1109 - recall_2: 0.9557 - val_loss: 0.1197 - val_recall_2: 0.9540\n",
            "Epoch 157/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1108 - recall_2: 0.9559 - val_loss: 0.1208 - val_recall_2: 0.9527\n",
            "Epoch 158/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1109 - recall_2: 0.9558 - val_loss: 0.1195 - val_recall_2: 0.9529\n",
            "Epoch 159/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1107 - recall_2: 0.9559 - val_loss: 0.1195 - val_recall_2: 0.9534\n",
            "Epoch 160/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1107 - recall_2: 0.9557 - val_loss: 0.1199 - val_recall_2: 0.9531\n",
            "Epoch 161/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1104 - recall_2: 0.9558 - val_loss: 0.1209 - val_recall_2: 0.9519\n",
            "Epoch 162/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1105 - recall_2: 0.9560 - val_loss: 0.1221 - val_recall_2: 0.9512\n",
            "Epoch 163/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1105 - recall_2: 0.9560 - val_loss: 0.1197 - val_recall_2: 0.9539\n",
            "Epoch 164/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1103 - recall_2: 0.9560 - val_loss: 0.1194 - val_recall_2: 0.9533\n",
            "Epoch 165/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1075 - recall_2: 0.9575 - val_loss: 0.1180 - val_recall_2: 0.9548\n",
            "Epoch 195/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1074 - recall_2: 0.9574 - val_loss: 0.1177 - val_recall_2: 0.9554\n",
            "Epoch 196/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1075 - recall_2: 0.9574 - val_loss: 0.1178 - val_recall_2: 0.9553\n",
            "Epoch 197/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1071 - recall_2: 0.9576 - val_loss: 0.1203 - val_recall_2: 0.9524\n",
            "Epoch 198/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1072 - recall_2: 0.9576 - val_loss: 0.1183 - val_recall_2: 0.9540\n",
            "Epoch 199/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1070 - recall_2: 0.9579 - val_loss: 0.1183 - val_recall_2: 0.9539\n",
            "Epoch 200/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1071 - recall_2: 0.9578 - val_loss: 0.1181 - val_recall_2: 0.9544\n",
            "Epoch 201/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1069 - recall_2: 0.9577 - val_loss: 0.1194 - val_recall_2: 0.9537\n",
            "Epoch 202/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1069 - recall_2: 0.9575 - val_loss: 0.1191 - val_recall_2: 0.9548\n",
            "Epoch 203/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1067 - recall_2: 0.9580 - val_loss: 0.1204 - val_recall_2: 0.9539\n",
            "Epoch 204/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1068 - recall_2: 0.9579 - val_loss: 0.1175 - val_recall_2: 0.9550\n",
            "Epoch 205/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1065 - recall_2: 0.9580 - val_loss: 0.1200 - val_recall_2: 0.9539\n",
            "Epoch 206/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1064 - recall_2: 0.9577 - val_loss: 0.1215 - val_recall_2: 0.9521\n",
            "Epoch 207/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1065 - recall_2: 0.9579 - val_loss: 0.1222 - val_recall_2: 0.9519\n",
            "Epoch 208/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1064 - recall_2: 0.9577 - val_loss: 0.1177 - val_recall_2: 0.9557\n",
            "Epoch 209/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1063 - recall_2: 0.9581 - val_loss: 0.1179 - val_recall_2: 0.9548\n",
            "Epoch 210/400\n",
            "349/349 [==============================] - 3s 7ms/step - loss: 0.1061 - recall_2: 0.9583 - val_loss: 0.1173 - val_recall_2: 0.9558\n",
            "Epoch 211/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1061 - recall_2: 0.9584 - val_loss: 0.1172 - val_recall_2: 0.9561\n",
            "Epoch 212/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1061 - recall_2: 0.9581 - val_loss: 0.1181 - val_recall_2: 0.9548\n",
            "Epoch 213/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1059 - recall_2: 0.9582 - val_loss: 0.1199 - val_recall_2: 0.9542\n",
            "Epoch 214/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1058 - recall_2: 0.9583 - val_loss: 0.1178 - val_recall_2: 0.9544\n",
            "Epoch 215/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1058 - recall_2: 0.9581 - val_loss: 0.1199 - val_recall_2: 0.9539\n",
            "Epoch 216/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1057 - recall_2: 0.9585 - val_loss: 0.1173 - val_recall_2: 0.9550\n",
            "Epoch 217/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1056 - recall_2: 0.9583 - val_loss: 0.1173 - val_recall_2: 0.9559\n",
            "Epoch 218/400\n",
            "349/349 [==============================] - 3s 8ms/step - loss: 0.1054 - recall_2: 0.9585 - val_loss: 0.1167 - val_recall_2: 0.9557\n",
            "Epoch 219/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1056 - recall_2: 0.9584 - val_loss: 0.1175 - val_recall_2: 0.9552\n",
            "Epoch 220/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1054 - recall_2: 0.9584 - val_loss: 0.1246 - val_recall_2: 0.9508\n",
            "Epoch 221/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1055 - recall_2: 0.9585 - val_loss: 0.1185 - val_recall_2: 0.9545\n",
            "Epoch 222/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1053 - recall_2: 0.9588 - val_loss: 0.1181 - val_recall_2: 0.9561\n",
            "Epoch 223/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1052 - recall_2: 0.9587 - val_loss: 0.1188 - val_recall_2: 0.9555\n",
            "Epoch 224/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1051 - recall_2: 0.9584 - val_loss: 0.1174 - val_recall_2: 0.9558\n",
            "Epoch 225/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1051 - recall_2: 0.9585 - val_loss: 0.1179 - val_recall_2: 0.9554\n",
            "Epoch 226/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1050 - recall_2: 0.9584 - val_loss: 0.1220 - val_recall_2: 0.9536\n",
            "Epoch 227/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1050 - recall_2: 0.9583 - val_loss: 0.1174 - val_recall_2: 0.9556\n",
            "Epoch 228/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1047 - recall_2: 0.9588 - val_loss: 0.1189 - val_recall_2: 0.9544\n",
            "Epoch 229/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1049 - recall_2: 0.9584 - val_loss: 0.1164 - val_recall_2: 0.9561\n",
            "Epoch 230/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1047 - recall_2: 0.9587 - val_loss: 0.1181 - val_recall_2: 0.9546\n",
            "Epoch 231/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1045 - recall_2: 0.9586 - val_loss: 0.1164 - val_recall_2: 0.9555\n",
            "Epoch 232/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1046 - recall_2: 0.9588 - val_loss: 0.1169 - val_recall_2: 0.9561\n",
            "Epoch 233/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1046 - recall_2: 0.9587 - val_loss: 0.1170 - val_recall_2: 0.9550\n",
            "Epoch 234/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1025 - recall_2: 0.9596 - val_loss: 0.1151 - val_recall_2: 0.9572\n",
            "Epoch 273/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1022 - recall_2: 0.9596 - val_loss: 0.1185 - val_recall_2: 0.9548\n",
            "Epoch 274/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1023 - recall_2: 0.9599 - val_loss: 0.1193 - val_recall_2: 0.9562\n",
            "Epoch 275/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1022 - recall_2: 0.9599 - val_loss: 0.1167 - val_recall_2: 0.9557\n",
            "Epoch 276/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1020 - recall_2: 0.9598 - val_loss: 0.1163 - val_recall_2: 0.9570\n",
            "Epoch 277/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1021 - recall_2: 0.9599 - val_loss: 0.1161 - val_recall_2: 0.9569\n",
            "Epoch 278/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1021 - recall_2: 0.9598 - val_loss: 0.1192 - val_recall_2: 0.9537\n",
            "Epoch 279/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1019 - recall_2: 0.9599 - val_loss: 0.1191 - val_recall_2: 0.9542\n",
            "Epoch 280/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1018 - recall_2: 0.9601 - val_loss: 0.1171 - val_recall_2: 0.9556\n",
            "Epoch 281/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1018 - recall_2: 0.9599 - val_loss: 0.1153 - val_recall_2: 0.9571\n",
            "Epoch 282/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1019 - recall_2: 0.9600 - val_loss: 0.1206 - val_recall_2: 0.9547\n",
            "Epoch 283/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1018 - recall_2: 0.9596 - val_loss: 0.1193 - val_recall_2: 0.9542\n",
            "Epoch 284/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1016 - recall_2: 0.9601 - val_loss: 0.1163 - val_recall_2: 0.9560\n",
            "Epoch 285/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1016 - recall_2: 0.9602 - val_loss: 0.1172 - val_recall_2: 0.9560\n",
            "Epoch 286/400\n",
            "349/349 [==============================] - 3s 7ms/step - loss: 0.1017 - recall_2: 0.9597 - val_loss: 0.1145 - val_recall_2: 0.9573\n",
            "Epoch 287/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1014 - recall_2: 0.9600 - val_loss: 0.1164 - val_recall_2: 0.9565\n",
            "Epoch 288/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1016 - recall_2: 0.9601 - val_loss: 0.1155 - val_recall_2: 0.9567\n",
            "Epoch 289/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1014 - recall_2: 0.9600 - val_loss: 0.1160 - val_recall_2: 0.9573\n",
            "Epoch 290/400\n",
            "349/349 [==============================] - 2s 7ms/step - loss: 0.1013 - recall_2: 0.9605 - val_loss: 0.1165 - val_recall_2: 0.9567\n",
            "Epoch 291/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1012 - recall_2: 0.9600 - val_loss: 0.1167 - val_recall_2: 0.9549\n",
            "Epoch 292/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1013 - recall_2: 0.9603 - val_loss: 0.1135 - val_recall_2: 0.9575\n",
            "Epoch 293/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1012 - recall_2: 0.9603 - val_loss: 0.1155 - val_recall_2: 0.9566\n",
            "Epoch 294/400\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1012 - recall_2: 0.9602 - val_loss: 0.1153 - val_recall_2: 0.9567\n",
            "Epoch 295/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1012 - recall_2: 0.9605 - val_loss: 0.1149 - val_recall_2: 0.9572\n",
            "Epoch 296/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1009 - recall_2: 0.9602 - val_loss: 0.1162 - val_recall_2: 0.9568\n",
            "Epoch 297/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1010 - recall_2: 0.9604 - val_loss: 0.1145 - val_recall_2: 0.9576\n",
            "Epoch 298/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1008 - recall_2: 0.9603 - val_loss: 0.1153 - val_recall_2: 0.9564\n",
            "Epoch 299/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1008 - recall_2: 0.9606 - val_loss: 0.1189 - val_recall_2: 0.9558\n",
            "Epoch 300/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1009 - recall_2: 0.9604 - val_loss: 0.1160 - val_recall_2: 0.9569\n",
            "Epoch 301/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1009 - recall_2: 0.9600 - val_loss: 0.1202 - val_recall_2: 0.9552\n",
            "Epoch 302/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1007 - recall_2: 0.9605 - val_loss: 0.1148 - val_recall_2: 0.9571\n",
            "Epoch 303/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1005 - recall_2: 0.9607 - val_loss: 0.1191 - val_recall_2: 0.9572\n",
            "Epoch 304/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1006 - recall_2: 0.9603 - val_loss: 0.1189 - val_recall_2: 0.9539\n",
            "Epoch 305/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1007 - recall_2: 0.9603 - val_loss: 0.1149 - val_recall_2: 0.9569\n",
            "Epoch 306/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1004 - recall_2: 0.9606 - val_loss: 0.1170 - val_recall_2: 0.9560\n",
            "Epoch 307/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1004 - recall_2: 0.9606 - val_loss: 0.1151 - val_recall_2: 0.9577\n",
            "Epoch 308/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1005 - recall_2: 0.9603 - val_loss: 0.1132 - val_recall_2: 0.9573\n",
            "Epoch 309/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1003 - recall_2: 0.9607 - val_loss: 0.1172 - val_recall_2: 0.9571\n",
            "Epoch 310/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1003 - recall_2: 0.9605 - val_loss: 0.1143 - val_recall_2: 0.9573\n",
            "Epoch 311/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1002 - recall_2: 0.9606 - val_loss: 0.1141 - val_recall_2: 0.9579\n",
            "Epoch 312/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1001 - recall_2: 0.9606 - val_loss: 0.1145 - val_recall_2: 0.9577\n",
            "Epoch 313/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1000 - recall_2: 0.9608 - val_loss: 0.1146 - val_recall_2: 0.9571\n",
            "Epoch 314/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1001 - recall_2: 0.9607 - val_loss: 0.1209 - val_recall_2: 0.9540\n",
            "Epoch 315/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.1001 - recall_2: 0.9609 - val_loss: 0.1145 - val_recall_2: 0.9577\n",
            "Epoch 316/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1001 - recall_2: 0.9607 - val_loss: 0.1162 - val_recall_2: 0.9560\n",
            "Epoch 317/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1000 - recall_2: 0.9605 - val_loss: 0.1155 - val_recall_2: 0.9577\n",
            "Epoch 318/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.1000 - recall_2: 0.9606 - val_loss: 0.1222 - val_recall_2: 0.9527\n",
            "Epoch 319/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0999 - recall_2: 0.9607 - val_loss: 0.1143 - val_recall_2: 0.9580\n",
            "Epoch 320/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0999 - recall_2: 0.9605 - val_loss: 0.1157 - val_recall_2: 0.9579\n",
            "Epoch 321/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0998 - recall_2: 0.9607 - val_loss: 0.1153 - val_recall_2: 0.9576\n",
            "Epoch 322/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0999 - recall_2: 0.9609 - val_loss: 0.1174 - val_recall_2: 0.9564\n",
            "Epoch 323/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0997 - recall_2: 0.9609 - val_loss: 0.1143 - val_recall_2: 0.9583\n",
            "Epoch 324/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0996 - recall_2: 0.9606 - val_loss: 0.1159 - val_recall_2: 0.9568\n",
            "Epoch 325/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0995 - recall_2: 0.9607 - val_loss: 0.1155 - val_recall_2: 0.9574\n",
            "Epoch 326/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0997 - recall_2: 0.9610 - val_loss: 0.1170 - val_recall_2: 0.9574\n",
            "Epoch 327/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0996 - recall_2: 0.9612 - val_loss: 0.1144 - val_recall_2: 0.9582\n",
            "Epoch 328/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0996 - recall_2: 0.9609 - val_loss: 0.1142 - val_recall_2: 0.9573\n",
            "Epoch 329/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0994 - recall_2: 0.9607 - val_loss: 0.1142 - val_recall_2: 0.9572\n",
            "Epoch 330/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0993 - recall_2: 0.9608 - val_loss: 0.1152 - val_recall_2: 0.9578\n",
            "Epoch 331/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0979 - recall_2: 0.9618 - val_loss: 0.1168 - val_recall_2: 0.9578\n",
            "Epoch 366/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0978 - recall_2: 0.9618 - val_loss: 0.1147 - val_recall_2: 0.9585\n",
            "Epoch 367/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0977 - recall_2: 0.9620 - val_loss: 0.1133 - val_recall_2: 0.9589\n",
            "Epoch 368/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0978 - recall_2: 0.9616 - val_loss: 0.1135 - val_recall_2: 0.9593\n",
            "Epoch 369/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0978 - recall_2: 0.9620 - val_loss: 0.1142 - val_recall_2: 0.9590\n",
            "Epoch 370/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0976 - recall_2: 0.9619 - val_loss: 0.1140 - val_recall_2: 0.9588\n",
            "Epoch 371/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0975 - recall_2: 0.9618 - val_loss: 0.1158 - val_recall_2: 0.9585\n",
            "Epoch 372/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0976 - recall_2: 0.9617 - val_loss: 0.1194 - val_recall_2: 0.9543\n",
            "Epoch 373/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0975 - recall_2: 0.9619 - val_loss: 0.1156 - val_recall_2: 0.9582\n",
            "Epoch 374/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0973 - recall_2: 0.9619 - val_loss: 0.1215 - val_recall_2: 0.9538\n",
            "Epoch 375/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0975 - recall_2: 0.9619 - val_loss: 0.1138 - val_recall_2: 0.9585\n",
            "Epoch 376/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0973 - recall_2: 0.9620 - val_loss: 0.1201 - val_recall_2: 0.9556\n",
            "Epoch 377/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0974 - recall_2: 0.9620 - val_loss: 0.1177 - val_recall_2: 0.9569\n",
            "Epoch 378/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0975 - recall_2: 0.9619 - val_loss: 0.1135 - val_recall_2: 0.9581\n",
            "Epoch 379/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0973 - recall_2: 0.9620 - val_loss: 0.1140 - val_recall_2: 0.9588\n",
            "Epoch 380/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0972 - recall_2: 0.9623 - val_loss: 0.1151 - val_recall_2: 0.9587\n",
            "Epoch 381/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0971 - recall_2: 0.9621 - val_loss: 0.1141 - val_recall_2: 0.9591\n",
            "Epoch 382/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0971 - recall_2: 0.9623 - val_loss: 0.1181 - val_recall_2: 0.9573\n",
            "Epoch 383/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0972 - recall_2: 0.9621 - val_loss: 0.1175 - val_recall_2: 0.9555\n",
            "Epoch 384/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0970 - recall_2: 0.9618 - val_loss: 0.1176 - val_recall_2: 0.9579\n",
            "Epoch 385/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0972 - recall_2: 0.9621 - val_loss: 0.1130 - val_recall_2: 0.9594\n",
            "Epoch 386/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0968 - recall_2: 0.9623 - val_loss: 0.1156 - val_recall_2: 0.9592\n",
            "Epoch 387/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0969 - recall_2: 0.9623 - val_loss: 0.1244 - val_recall_2: 0.9532\n",
            "Epoch 388/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0971 - recall_2: 0.9624 - val_loss: 0.1180 - val_recall_2: 0.9573\n",
            "Epoch 389/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0969 - recall_2: 0.9622 - val_loss: 0.1135 - val_recall_2: 0.9592\n",
            "Epoch 390/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0969 - recall_2: 0.9624 - val_loss: 0.1195 - val_recall_2: 0.9564\n",
            "Epoch 391/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0968 - recall_2: 0.9622 - val_loss: 0.1130 - val_recall_2: 0.9595\n",
            "Epoch 392/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0967 - recall_2: 0.9621 - val_loss: 0.1149 - val_recall_2: 0.9579\n",
            "Epoch 393/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0969 - recall_2: 0.9622 - val_loss: 0.1137 - val_recall_2: 0.9595\n",
            "Epoch 394/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0967 - recall_2: 0.9623 - val_loss: 0.1133 - val_recall_2: 0.9586\n",
            "Epoch 395/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0968 - recall_2: 0.9623 - val_loss: 0.1141 - val_recall_2: 0.9585\n",
            "Epoch 396/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0967 - recall_2: 0.9624 - val_loss: 0.1159 - val_recall_2: 0.9575\n",
            "Epoch 397/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0967 - recall_2: 0.9625 - val_loss: 0.1202 - val_recall_2: 0.9545\n",
            "Epoch 398/400\n",
            "349/349 [==============================] - 2s 5ms/step - loss: 0.0965 - recall_2: 0.9623 - val_loss: 0.1151 - val_recall_2: 0.9567\n",
            "Epoch 399/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0966 - recall_2: 0.9623 - val_loss: 0.1138 - val_recall_2: 0.9591\n",
            "Epoch 400/400\n",
            "349/349 [==============================] - 2s 6ms/step - loss: 0.0967 - recall_2: 0.9621 - val_loss: 0.1128 - val_recall_2: 0.9595\n"
          ]
        }
      ],
      "source": [
        "# Training the network (batch_size= 500, epoch = 500)\n",
        "print('\\nFitting DNN (Detection Module):\\n')\n",
        "batch_size1 = 500\n",
        "history_detection = model_detection.fit(X_trn_detection, t_trn_detection, epochs=400,\n",
        "                                validation_split=.2, batch_size = batch_size1,\n",
        "                                callbacks=callbacks_list, verbose=1)"
      ],
      "id": "mhfuF8vYTEau"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JE4lGm08TEav",
        "outputId": "4d3225f0-4b4d-4634-c8c4-6b477c0c7a5e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x1598167a888>"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plotting the variation of loss function on both training and validation set: \n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "val_loss = history_detection.history[\"val_loss\"]\n",
        "loss = history_detection.history[\"loss\"]\n",
        "\n",
        "epochs = range(1, 401)\n",
        "plt.plot(epochs, val_loss[:], \"r-\",\n",
        "label=\"Validation Loss\")\n",
        "plt.plot(epochs, loss[:], \"b-\",\n",
        "label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "id": "JE4lGm08TEav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aEjesPZXTEav"
      },
      "outputs": [],
      "source": [
        "# Testing the trained network over the testset.\n",
        "predictions_label = model_detection.predict(X_tst_detection)\n",
        "\n",
        "# Using argmax function to select the label with the highest probability.\n",
        "y_pred = np.zeros([len(X_tst_detection),1])\n",
        "for i in range(len(X_tst_detection)):\n",
        "    y_pred[i,0] = np.argmax(predictions_label[i])"
      ],
      "id": "aEjesPZXTEav"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r3mSOZzITEav"
      },
      "source": [
        "### Metrics"
      ],
      "id": "r3mSOZzITEav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wEz-7i1LTEav",
        "outputId": "75713790-7216-4ff1-e4b8-59ad4f4cf04b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            " For Rainfall Detection Over Land:\n",
            "\n",
            "Precision:  0.9995261480141294\n",
            "Accuracy:  0.9998607585446054\n",
            "Recall (TPR):  0.9999138116785176\n",
            "False Alarm (FPR):  0.00015678896205707118\n",
            "\n",
            "F1 Score:  0.9997199422650209\n",
            "----------------------------\n",
            "\n",
            " For Snwofall Detection Over Land:\n",
            "\n",
            "Precision:  0.9073302790503956\n",
            "Accuracy:  0.9595128691237428\n",
            "Recall (TPR):  0.93337617823479\n",
            "False Alarm (FPR):  0.03177527383859589\n",
            "\n",
            "F1 Score:  0.920168954593453\n",
            "----------------------------\n",
            "\n",
            " For Model Detection Over Land:\n",
            "\n",
            "Precision:  0.9594057603119008\n",
            "Recall (TPR):  0.9594057603119008\n",
            "\n",
            "F1 Score:  0.9594057603119008\n"
          ]
        }
      ],
      "source": [
        "### Detection Module\n",
        "\n",
        "n_cc=1\n",
        "n_cs=1\n",
        "n_cr=1\n",
        "n_sc=1\n",
        "n_ss=1\n",
        "n_sr=1\n",
        "n_rc=1\n",
        "n_rs=1\n",
        "n_rr=1\n",
        "\n",
        "precip_c= 0\n",
        "precip_r= 1\n",
        "precip_s= 2\n",
        "\n",
        "for i in range(len(X_tst_detection)):\n",
        "    label_predict = y_pred[i]\n",
        "    label_actual = t_test[i]\n",
        "    if label_predict==precip_c and label_actual==precip_c:\n",
        "        n_cc+=1\n",
        "    if label_predict==precip_s and label_actual==precip_s:\n",
        "        n_ss+=1\n",
        "    if label_predict==precip_r and label_actual==precip_r:\n",
        "        n_rr+=1 \n",
        "    if label_predict==precip_c and label_actual==precip_s:\n",
        "        n_cs+=1\n",
        "    if label_predict==precip_c and label_actual==precip_r:\n",
        "        n_cr+=1\n",
        "    if label_predict==precip_s and label_actual==precip_c:\n",
        "        n_sc+=1\n",
        "    if label_predict==precip_s and label_actual==precip_r:\n",
        "        n_sr+=1  \n",
        "    if label_predict==precip_r and label_actual==precip_c:\n",
        "        n_rc+=1\n",
        "    if label_predict==precip_r and label_actual==precip_s:\n",
        "        n_rs+=1        \n",
        "        \n",
        "#Snow\n",
        "TP_s = n_ss\n",
        "TN_s = n_cc+n_cr+n_rc+n_rr\n",
        "FP_s = n_sc+n_sr\n",
        "FN_s = n_cs+n_rs\n",
        "\n",
        "precision_s = TP_s/(TP_s+FP_s)\n",
        "acc_s = (TP_s+TN_s)/(TP_s+TN_s+FP_s+FN_s)\n",
        "recall_s = TP_s/(TP_s+FN_s)\n",
        "f1_score_s = (2*precision_s*recall_s)/(precision_s+recall_s)\n",
        "FPR_s = FP_s/(FP_s+TN_s)\n",
        "\n",
        "#Rain\n",
        "TP_r = n_rr\n",
        "TN_r = n_cc+n_cs+n_sc+n_ss\n",
        "FP_r = n_rc+n_rs\n",
        "FN_r = n_cr+n_sr\n",
        "\n",
        "precision_r = TP_r/(TP_r+FP_r)\n",
        "acc_r = (TP_r+TN_r)/(TP_r+TN_r+FP_r+FN_r)\n",
        "recall_r = TP_r/(TP_r+FN_r)\n",
        "f1_score_r = (2*precision_r*recall_r)/(precision_r+recall_r)\n",
        "FPR_r = FP_r/(FP_r+TN_r) \n",
        "\n",
        "print('\\n For Rainfall Detection Over Land:\\n')\n",
        "print('Precision: ',precision_r)\n",
        "print('Accuracy: ',acc_r)\n",
        "print('Recall (TPR): ',recall_r)\n",
        "print('False Alarm (FPR): ',FPR_r)\n",
        "print('\\nF1 Score: ',f1_score_r)\n",
        "\n",
        "print('----------------------------')\n",
        "print('\\n For Snwofall Detection Over Land:\\n')\n",
        "print('Precision: ',precision_s)\n",
        "print('Accuracy: ',acc_s)\n",
        "print('Recall (TPR): ',recall_s)\n",
        "print('False Alarm (FPR): ',FPR_s)\n",
        "print('\\nF1 Score: ',f1_score_s)\n",
        "\n",
        "#Model\n",
        "TP = n_cc+n_ss+n_rr\n",
        "FP = n_cs+n_cr+n_sc+n_sr+n_rc+n_rs\n",
        "FN = n_sc+n_rc+n_cs+n_rs+n_cr+n_sr\n",
        "\n",
        "precision = TP/(TP+FP)\n",
        "recall = TP/(TP+FN)\n",
        "f1_score = (2*precision*recall)/(precision+recall)\n",
        "\n",
        "print('----------------------------')\n",
        "print('\\n For Model Detection Over Land:\\n')\n",
        "print('Precision: ',precision)\n",
        "print('Recall (TPR): ',recall)\n",
        "print('\\nF1 Score: ',f1_score)"
      ],
      "id": "wEz-7i1LTEav"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAC6u52ZTEaw",
        "outputId": "5b543e5a-5963-45fd-c2ef-8ec4029c96a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "187/187 [==============================] - 0s 2ms/step - loss: 0.1089 - recall_2: 0.9595\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[0.1088700145483017, 0.9594660997390747]"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model_detection.evaluate(X_tst_detection, t_tst_detection, batch_size = batch_size1)"
      ],
      "id": "fAC6u52ZTEaw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H7Y60hlVTEaw"
      },
      "source": [
        "## **2.2 - Estimation networks (e-DNN)**"
      ],
      "id": "H7Y60hlVTEaw"
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mMjQ20kiTEaw"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras import backend\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "        return backend.sqrt(backend.mean(backend.square(y_pred-y_true)))\n",
        "    \n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "        return backend.mean(backend.abs(y_pred-y_true))        "
      ],
      "id": "mMjQ20kiTEaw"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S0UdJgzUTEaw"
      },
      "source": [
        "### **2.2.1 Snowfall retrieval**"
      ],
      "id": "S0UdJgzUTEaw"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cakbx_kNTEax"
      },
      "outputs": [],
      "source": [
        "# Parameters\n",
        "hidden_units = 60\n",
        "dropout = 0\n",
        "\n",
        "# LAND\n",
        "model_retrieval = Sequential()\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(hidden_units))\n",
        "model_retrieval.add(Activation('relu'))\n",
        "model_retrieval.add(Dropout(dropout))\n",
        "\n",
        "model_retrieval.add(Dense(1))\n",
        "model_retrieval.add(Activation('relu'))"
      ],
      "id": "cakbx_kNTEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnBTYuJITEax"
      },
      "outputs": [],
      "source": [
        "model_retrieval.compile(optimizer = tf.keras.optimizers.RMSprop(learning_rate=0.00001),\n",
        "              loss = root_mean_squared_error,\n",
        "              metrics= mean_absolute_error)"
      ],
      "id": "QnBTYuJITEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ijLKEfyiTEax"
      },
      "outputs": [],
      "source": [
        "from tensorflow import keras\n",
        "callbacks_list = [\n",
        "    keras.callbacks.EarlyStopping(\n",
        "    monitor=\"val_loss\",\n",
        "    patience=25,),\n",
        "    keras.callbacks.ModelCheckpoint(\n",
        "    filepath=\"checkpoint_path.keras\",\n",
        "    monitor=\"val_loss\",\n",
        "    mode=\"min\",\n",
        "    save_best_only=True,\n",
        "    )    \n",
        "]"
      ],
      "id": "ijLKEfyiTEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z3389rUQTEax"
      },
      "outputs": [],
      "source": [
        "print('\\nFitting DNN (Retrieval Module - Snow):\\n')\n",
        "batch_size2 = 500\n",
        "history_retrieval = model_retrieval.fit(X_trn_retrieval, y_trn_retrieval, epochs=400,\n",
        "                                validation_split=.2, batch_size = batch_size2,\n",
        "                                callbacks=callbacks_list, verbose=1)"
      ],
      "id": "z3389rUQTEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QajunlhMTEax"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "val_loss = history_retrieval.history[\"val_loss\"]\n",
        "loss = history_retrieval.history[\"loss\"]\n",
        "\n",
        "epochs = range(1, 258)\n",
        "plt.plot(epochs, val_loss[:], \"r-\",\n",
        "label=\"Validation Loss\")\n",
        "plt.plot(epochs, loss[:], \"b-\",\n",
        "label=\"Training Loss\")\n",
        "plt.xlabel(\"Epochs\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()"
      ],
      "id": "QajunlhMTEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oHI75hTHTEax"
      },
      "outputs": [],
      "source": [
        "predictions_snow = model_retrieval.predict(X_tst_retrieval)"
      ],
      "id": "oHI75hTHTEax"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5DkTNhFJTEay"
      },
      "outputs": [],
      "source": [
        "model_retrieval.evaluate(X_tst_retrieval, y_tst_retrieval, batch_size = batch_size2)"
      ],
      "id": "5DkTNhFJTEay"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Saving the models**"
      ],
      "metadata": {
        "id": "gAKFvx1-cE_Q"
      },
      "id": "gAKFvx1-cE_Q"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K77L0AWzTEaz"
      },
      "outputs": [],
      "source": [
        "import scipy\n",
        "from scipy.io import savemat\n",
        "\n",
        "model_detection.save('Models\\CPR\\Land\\model_dtc',save_format='h5')\n",
        "model_retrieval.save('Models\\CPR\\Land\\model_snow',save_format='h5')\n",
        "\n",
        "fp_CPR_land = 'Models/CPR/land/files_CPR_land.mat'\n",
        "scipy.io.savemat(fp_CPR_land, {'mean_detection_CPR_land': mean_detection,'std_detection_CPR_land':std_detection,\n",
        "                               'mean_snow_retrieval_CPR_land': mean_retrieval,'std_snow_retrieval_CPR_land':std_retrieval})"
      ],
      "id": "K77L0AWzTEaz"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}